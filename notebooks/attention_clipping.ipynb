{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, random, math, os, sys, tqdm\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from trainer.classification import Trainer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 216214.24it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 180949.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert\n",
      "Trainer.load: Loading...\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(batch_size=8)\n",
    "trainer.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = trainer.get_batch()\n",
    "trainer.model = trainer.model.eval()\n",
    "bert = trainer.model.bert\n",
    "fc = trainer.model.classifier\n",
    "\n",
    "def eval(model, batch=batch, fc=fc):\n",
    "    lm_output = model(\n",
    "        input_ids = batch.input_ids, \n",
    "        attention_mask = batch.attention_masks, \n",
    "        output_hidden_states=True,\n",
    "        output_attentions=True,\n",
    "    )\n",
    "    last_hidden = lm_output.last_hidden_state[:,0,:]\n",
    "    x = fc(last_hidden)\n",
    "    return torch.argmax(x, dim=-1), batch.labels, lm_output\n",
    "output, labels, lm_output = eval(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 34, torch.Size([8, 4, 71, 71]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAYER = -1\n",
    "BATCH = 0\n",
    "HEAD = 0\n",
    "N = torch.sum(batch.attention_masks[BATCH]).item()\n",
    "\n",
    "plt.imshow(lm_output.attentions[LAYER][BATCH][HEAD][:N, :N].detach().cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "torch.sum(lm_output.attentions[LAYER][BATCH][HEAD][0,:N]).item(), N, lm_output.attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impact factor torch.Size([34])\n",
      "hign impact [33  0 27 18  7]\n",
      "0.002999544143676758\n",
      "tensor([33,  0, 27, 18,  7, 17, 12, 29, 24, 32,  6, 16,  8, 25, 13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 27, 33, 14, 21, 31,  7,  5, 16,  8,  6, 18, 29, 25,  4, 32, 13, 28,\n",
      "        17, 12,  1, 24], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NBATCH = batch.input_ids.shape[0]\n",
    "LAYER = 3\n",
    "attend_tokens = [0]\n",
    "\n",
    "a = lm_output.attentions[LAYER][BATCH][:,:N, :N]\n",
    "a = torch.sum(a, dim=0)\n",
    "a = a[attend_tokens,:]\n",
    "a = torch.sum(a, dim=0)\n",
    "print('impact factor', a.shape)\n",
    "b = torch.topk(a, 5)[1]\n",
    "print('hign impact', b.cpu().numpy())\n",
    "# plt.bar(range(N), a.detach().cpu().numpy())\n",
    "# plt.show()\n",
    "\n",
    "#this is very evil code...\n",
    "def update_input_mask_from_previous_attention(attention_mask, previous_attention, output_token_indices, output_token_impact, k=5):\n",
    "    NBATCH = attention_mask.shape[0]\n",
    "\n",
    "    input_indcies = []\n",
    "    input_impacts = []\n",
    "    for i, idxs in enumerate(output_token_indices):\n",
    "        N = int(torch.sum((attention_mask[i]==0)*1.0).item())\n",
    "        \n",
    "        #print(i, previous_attention, N)\n",
    "        a = previous_attention[i,:,:N,:N]\n",
    "        #print(a.shape, N, previous_attention.shape)\n",
    "        a = torch.sum(a, dim=0)\n",
    "        #print(idxs, a.shape)\n",
    "        a = a[idxs, :] * output_token_impact[i].view(-1, 1)\n",
    "        a = torch.sum(a, dim=0)\n",
    "        \n",
    "        #print(f'k {k}, a {a.shape}')\n",
    "        kxx = k\n",
    "        if k < 1.0: kxx = int(math.ceil(k*N))\n",
    "        b, c = torch.topk(a, min(N, kxx))\n",
    "        input_indcies.append(c)\n",
    "        input_impacts.append(b)\n",
    "    \n",
    "    input_mask = torch.zeros(NBATCH, attention_mask.shape[-1], device=previous_attention.device, dtype=previous_attention.dtype)\n",
    "    for i, idxs in enumerate(input_indcies):\n",
    "        for k in idxs:\n",
    "            input_mask[i, k] = 1.0\n",
    "    \n",
    "    return input_mask, input_indcies, input_impacts\n",
    "\n",
    "def update_input_mask_from_previous_attention(\n",
    "    attention_mask, \n",
    "    previous_attention, \n",
    "    output_token_indices, \n",
    "    output_token_impact, \n",
    "    k=0.5\n",
    "):\n",
    "    assert k <= 1.0\n",
    "    attention_mask_shape = attention_mask.shape\n",
    "    NBATCH = attention_mask_shape[0]\n",
    "    TLEN = attention_mask_shape[-1]\n",
    "    dtype = previous_attention.dtype\n",
    "    device = previous_attention.device\n",
    "    kxx = int(math.ceil(k*TLEN))\n",
    "\n",
    "    input_mask = torch.zeros(\n",
    "        NBATCH, TLEN, \n",
    "        device=device, \n",
    "        dtype=dtype\n",
    "    )\n",
    "    \n",
    "    att = torch.sum(previous_attention, dim=1)\n",
    "    att = torch.gather(att, 1, output_token_indices.unsqueeze(-1).expand(NBATCH, output_token_indices.shape[1], TLEN))\n",
    "    att = att * output_token_impact.unsqueeze(-1)\n",
    "    att = torch.sum(att, dim=1)\n",
    "    #att(N, TLEN)\n",
    "    input_impacts, input_indices = torch.topk(att, kxx, dim=1)\n",
    "    #input_impacts(N, K), input_indices(N, K)\n",
    "    \n",
    "    input_mask.scatter_(1, input_indices, 1.0)\n",
    "    #input_mask (N, TLEN)\n",
    "    \n",
    "    return input_mask, input_indices, input_impacts\n",
    "\n",
    "t = time.time()\n",
    "mask, indices, impacts = update_input_mask_from_previous_attention(\n",
    "    batch.attention_masks - 1.0, \n",
    "    lm_output.attentions[LAYER], \n",
    "    torch.zeros(NBATCH, 1, device=batch.device, dtype=torch.int64), \n",
    "    torch.ones(NBATCH, 1, device=batch.device, dtype=torch.float32), \n",
    "    k=0.2\n",
    ")\n",
    "mask2, indices2, impacts2 = update_input_mask_from_previous_attention(\n",
    "    batch.attention_masks - 1.0, \n",
    "    lm_output.attentions[LAYER-1], \n",
    "    indices, \n",
    "    impacts, \n",
    "    k=0.3\n",
    ")\n",
    "print(time.time() - t)\n",
    "mask2.shape, batch.attention_masks.shape\n",
    "def plot_grid(grid):\n",
    "    plt.imshow(grid.cpu().detach().numpy())\n",
    "    #plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "print(indices[0])\n",
    "last_output_attentions = torch.sum(lm_output.attentions[LAYER][0], dim=0)[[0], :N]\n",
    "plot_grid(last_output_attentions)\n",
    "plot_grid(mask[0][:N].view(1,-1))\n",
    "last_output_attentions_input_masked = last_output_attentions * mask[0][:N]\n",
    "plot_grid(last_output_attentions_input_masked)\n",
    "\n",
    "print(indices2[0])\n",
    "second_output_attentions = torch.sum(lm_output.attentions[LAYER-1][0], dim=0)[indices[0],:N]*impacts[0].view(-1,1)\n",
    "plot_grid(second_output_attentions)\n",
    "second_output_attentions_impact = torch.sum(second_output_attentions, dim=0).view(1,-1)\n",
    "plot_grid(second_output_attentions_impact)\n",
    "plot_grid(mask2[0][:N].view(1,-1))\n",
    "plot_grid(second_output_attentions_impact * mask2[0][:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, torch\n",
    "import torch.utils.checkpoint\n",
    "from packaging import version\n",
    "from torch import nn\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    ")\n",
    "from transformers.modeling_utils import (\n",
    "    PreTrainedModel,\n",
    "    apply_chunking_to_forward,\n",
    "    find_pruneable_heads_and_indices,\n",
    "    prune_linear_layer,\n",
    ")\n",
    "from transformers.utils import logging\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertEmbeddings\n",
    "\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({config.num_attention_heads})\"\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        self.position_embedding_type = position_embedding_type or getattr(\n",
    "            config, \"position_embedding_type\", \"absolute\"\n",
    "        )\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            raise Exception('removed')\n",
    "\n",
    "        self.is_decoder = config.is_decoder\n",
    "        if self.is_decoder: raise Exception()\n",
    "\n",
    "        self.print = True\n",
    "        self.reset_input_mask()\n",
    "        self.attention_masking_timing = 'after_softmax'\n",
    "        self.output_masking = True\n",
    "    \n",
    "    def reset_input_mask(self):\n",
    "        self.input_mask = None\n",
    "        self.input_indices = None\n",
    "        self.input_impacts = None\n",
    "        self.output_mask = None\n",
    "    \n",
    "    def update_input_mask_from_previous_attention(self, output_token_mask, output_token_indices, output_token_impact, k):\n",
    "        input_mask, input_indcies, input_impacts = update_input_mask_from_previous_attention(\n",
    "            self.last_attention_mask, \n",
    "            self.last_attention_probs, \n",
    "            output_token_indices, \n",
    "            output_token_impact, \n",
    "            k\n",
    "        )\n",
    "        self.input_mask = input_mask\n",
    "        self.input_indices = input_indcies\n",
    "        self.input_impacts = input_impacts\n",
    "        self.output_mask = output_token_mask\n",
    "        return input_mask, input_indcies, input_impacts\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        if self.is_decoder: raise Exception()\n",
    "        if not self.attention_masking_timing in ['after_softmax', 'before_softmax']: raise Exception()\n",
    "        self.last_hidden_states = hidden_states\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        \n",
    "        is_cross_attention = encoder_hidden_states is not None\n",
    "\n",
    "        if (is_cross_attention and past_key_value is not None) or is_cross_attention or (past_key_value is not None):\n",
    "            raise Exception()\n",
    "        else:\n",
    "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            raise Exception()\n",
    "\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        if self.input_mask is not None and self.attention_masking_timing == 'before_softmax':\n",
    "            if self.print: print(f'apply input mask, before softmax. input_mask:{self.input_mask.shape}, attention_scores:{attention_scores.shape}')\n",
    "            attention_scores = attention_scores + (1.0 - self.input_mask.view(self.input_mask.shape[0], 1, 1, self.input_mask.shape[-1])) * -10000\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "        \n",
    "        if self.print: print('SelfAttention.forward: last_attention_probs backuped')\n",
    "        self.last_attention_probs = attention_probs.detach().clone()\n",
    "        self.last_attention_mask = attention_mask.detach().clone()\n",
    "\n",
    "        if self.input_mask is not None and self.attention_masking_timing == 'after_softmax':\n",
    "            if self.print: print(f'apply input mask, after softmax. input_mask:{self.input_mask.shape}, attention_probs:{attention_probs.shape}')\n",
    "            attention_probs = attention_probs * self.input_mask.view(self.input_mask.shape[0], 1, 1, self.input_mask.shape[-1])\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        if self.output_mask is not None and self.output_masking:\n",
    "            output_mask = self.output_mask.unsqueeze(-1)\n",
    "            if self.print: print(f'apply output mask. mask:{output_mask.shape} context:{context_layer.shape}')\n",
    "            context_layer = context_layer * output_mask\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(config, position_embedding_type=position_embedding_type)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(\n",
    "            heads, self.self.num_attention_heads, self.self.attention_head_size, self.pruned_heads\n",
    "        )\n",
    "\n",
    "        # Prune linear layers\n",
    "        self.self.query = prune_linear_layer(self.self.query, index)\n",
    "        self.self.key = prune_linear_layer(self.self.key, index)\n",
    "        self.self.value = prune_linear_layer(self.self.value, index)\n",
    "        self.output.dense = prune_linear_layer(self.output.dense, index, dim=1)\n",
    "\n",
    "        # Update hyper params and store pruned heads\n",
    "        self.self.num_attention_heads = self.self.num_attention_heads - len(heads)\n",
    "        self.self.all_head_size = self.self.attention_head_size * self.self.num_attention_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        self_outputs = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            past_key_value,\n",
    "            output_attentions,\n",
    "        )\n",
    "        attention_output = self.output(self_outputs[0], hidden_states)\n",
    "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = BertAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        self.add_cross_attention = config.add_cross_attention\n",
    "        if self.add_cross_attention:\n",
    "            if not self.is_decoder:\n",
    "                raise ValueError(f\"{self} should be used as a decoder model if cross attention is added\")\n",
    "            self.crossattention = BertAttention(config, position_embedding_type=\"absolute\")\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            past_key_value=self_attn_past_key_value,\n",
    "        )\n",
    "        self.self_attention_outputs = self_attention_outputs\n",
    "        attention_output = self_attention_outputs[0]\n",
    "\n",
    "        # if decoder, the last output is tuple of self-attn cache\n",
    "        if self.is_decoder: raise Exception()\n",
    "        else: outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        cross_attn_present_key_value = None\n",
    "        if self.is_decoder and encoder_hidden_states is not None: raise Exception()\n",
    "\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        self.layer_output = layer_output\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "        # if decoder, return the attn key/values as the last output\n",
    "        if self.is_decoder: raise Exception()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_values=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        return_dict=True,\n",
    "    ):\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
    "\n",
    "        next_decoder_cache = () if use_cache else None\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "\n",
    "                if use_cache:\n",
    "                    logger.warning(\n",
    "                        \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
    "                    )\n",
    "                    use_cache = False\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs, past_key_value, output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    encoder_hidden_states,\n",
    "                    encoder_attention_mask,\n",
    "                    past_key_value,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if use_cache:\n",
    "                next_decoder_cache += (layer_outputs[-1],)\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "                if self.config.add_cross_attention:\n",
    "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    next_decoder_cache,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                    all_cross_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=next_decoder_cache,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=all_cross_attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "\n",
    "class BertPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
    "    models.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = BertConfig\n",
    "    #load_tf_weights = load_tf_weights_in_bert\n",
    "    base_model_prefix = \"bert\"\n",
    "    supports_gradient_checkpointing = True\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize the weights\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def _set_gradient_checkpointing(self, module, value=False):\n",
    "        if isinstance(module, BertEncoder):\n",
    "            module.gradient_checkpointing = value\n",
    "\n",
    "\n",
    "class BertModel(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "\n",
    "    The model can behave as an encoder (with only self-attention) as well as a decoder, in which case a layer of\n",
    "    cross-attention is added between the self-attention layers, following the architecture described in [Attention is\n",
    "    all you need](https://arxiv.org/abs/1706.03762) by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,\n",
    "    Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n",
    "\n",
    "    To behave as an decoder the model needs to be initialized with the `is_decoder` argument of the configuration set\n",
    "    to `True`. To be used in a Seq2Seq model, the model needs to initialized with both `is_decoder` argument and\n",
    "    `add_cross_attention` set to `True`; an `encoder_hidden_states` is then expected as an input to the forward pass.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, add_pooling_layer=True):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "\n",
    "        self.pooler = BertPooler(config) if add_pooling_layer else None\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
    "        class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "            \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_values=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "            the model is configured as a decoder.\n",
    "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "        use_cache (`bool`, *optional*):\n",
    "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "            `past_key_values`).\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if self.config.is_decoder:\n",
    "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        else:\n",
    "            use_cache = False\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        # past_key_values_length\n",
    "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape, device)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids,\n",
    "            position_ids=position_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            past_key_values_length=past_key_values_length,\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values=encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfAttention.forward: last_attention_probs backuped\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "SelfAttention.forward: last_attention_probs backuped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 4, 1, 3, 4, 3, 3], device='cuda:0'),\n",
       " tensor([1, 2, 4, 1, 3, 4, 3, 3], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsebert = BertModel(trainer.model.bert.config)\n",
    "sparsebert = sparsebert.to(trainer.device)\n",
    "sparsebert = sparsebert.eval()\n",
    "sparsebert.load_state_dict(bert.state_dict())\n",
    "eval(sparsebert)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfAttention.forward: last_attention_probs backuped\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 4, 1, 3, 4, 3, 3], device='cuda:0'),\n",
       " tensor([1, 2, 4, 1, 3, 4, 3, 3], device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_print(sparsebert, v):\n",
    "    for layer in sparsebert.encoder.layer:\n",
    "        layer.attention.self.print = v\n",
    "\n",
    "def set_masking_timing(sparsebert, v):\n",
    "    for layer in sparsebert.encoder.layer:\n",
    "        layer.attention.self.attention_masking_timing = v\n",
    "\n",
    "def set_output_masking(sparsebert, v):\n",
    "    for layer in sparsebert.encoder.layer:\n",
    "        layer.attention.self.output_masking = v\n",
    "\n",
    "def update_input_mask(sparsebert, ks=[0.999,0.5,0.25,0.1]):\n",
    "    dtype = sparsebert.encoder.layer[0].attention.self.last_attention_probs.dtype\n",
    "    device = sparsebert.encoder.layer[0].attention.self.last_attention_probs.device\n",
    "    batch_size = sparsebert.encoder.layer[0].attention.self.last_attention_mask.shape[0]\n",
    "    token_len = sparsebert.encoder.layer[0].attention.self.last_attention_mask.shape[-1]\n",
    "    mask = torch.zeros(batch_size, token_len, dtype=dtype, device=device)\n",
    "    mask[:,0] = 1.0\n",
    "    indices = torch.zeros(batch_size, 1, dtype=torch.int64, device=device)\n",
    "    impacts = torch.ones(batch_size, 1, dtype=dtype, device=device)\n",
    "    L = len(sparsebert.encoder.layer)\n",
    "    for i in range(L):\n",
    "        mask, indices, impacts = sparsebert.encoder.layer[L-i-1].attention.self.update_input_mask_from_previous_attention(\n",
    "            output_token_mask = mask,\n",
    "            output_token_indices = indices,\n",
    "            output_token_impact = impacts,\n",
    "            k = ks[L-i-1],\n",
    "        )\n",
    "\n",
    "def reset_input_mask(sparsebert):\n",
    "    for layer in sparsebert.encoder.layer:\n",
    "        layer.attention.self.reset_input_mask()\n",
    "\n",
    "set_print(sparsebert, True)\n",
    "set_output_masking(sparsebert, False)\n",
    "set_masking_timing(sparsebert, 'before_softmax')\n",
    "reset_input_mask(sparsebert)\n",
    "eval(sparsebert)\n",
    "update_input_mask(sparsebert)\n",
    "ret = eval(sparsebert)[:2]\n",
    "reset_input_mask(sparsebert)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 104.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93475"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(bert, eval=eval, N=1000):\n",
    "    trainer.seed()\n",
    "    acc_sum = 0\n",
    "    N = N\n",
    "    for i in tqdm.tqdm(range(N)):\n",
    "        batch = trainer.get_batch(test=True)\n",
    "        output, label, _ = eval(bert, batch=batch)\n",
    "        acc_sum += torch.mean((output == label) * 1.0)\n",
    "    return acc_sum.item() / N\n",
    "accuracy(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:04<00:00, 15.39it/s]\n",
      "100%|██████████| 1000/1000 [01:04<00:00, 15.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('output mask: False', 0.92425, 0.9275)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sparse_eval(sparsebert, batch=batch):\n",
    "    reset_input_mask(sparsebert)\n",
    "    eval(sparsebert, batch=batch)\n",
    "    update_input_mask(sparsebert)\n",
    "    ret = eval(sparsebert, batch=batch)\n",
    "    return ret\n",
    "set_output_masking(sparsebert, False)\n",
    "set_masking_timing(sparsebert, 'after_softmax')\n",
    "set_print(sparsebert, False)\n",
    "acc_after = accuracy(sparsebert, eval=sparse_eval)\n",
    "set_print(sparsebert, True)\n",
    "set_masking_timing(sparsebert, 'before_softmax')\n",
    "set_print(sparsebert, False)\n",
    "acc_before = accuracy(sparsebert, eval=sparse_eval)\n",
    "set_print(sparsebert, True)\n",
    "'output mask: False', acc_after, acc_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:05<00:00, 15.26it/s]\n",
      "100%|██████████| 1000/1000 [01:05<00:00, 15.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('output mask: True', 0.915625, 0.924625)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_output_masking(sparsebert, True)\n",
    "set_masking_timing(sparsebert, 'after_softmax') #this must be wrong.\n",
    "set_print(sparsebert, False)\n",
    "acc_after = accuracy(sparsebert, eval=sparse_eval)\n",
    "set_print(sparsebert, True)\n",
    "set_masking_timing(sparsebert, 'before_softmax')\n",
    "set_print(sparsebert, False)\n",
    "acc_before = accuracy(sparsebert, eval=sparse_eval)\n",
    "set_print(sparsebert, True)\n",
    "'output mask: True', acc_after, acc_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention MSE, after softmax tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Attention MSE, befo softmax tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "set_print(sparsebert, False)\n",
    "set_masking_timing(sparsebert, 'after_softmax')\n",
    "reset_input_mask(sparsebert)\n",
    "_,_, lm_output = eval(sparsebert, batch=batch)\n",
    "update_input_mask(sparsebert)\n",
    "_,_, lm_output_sparse = eval(sparsebert, batch=batch)\n",
    "reset_input_mask(sparsebert)\n",
    "print('Attention MSE, after softmax', torch.mean(torch.square(lm_output.attentions[-1]-lm_output_sparse.attentions[-1])))\n",
    "\n",
    "set_masking_timing(sparsebert, 'before_softmax')\n",
    "reset_input_mask(sparsebert)\n",
    "_,_, lm_output = eval(sparsebert, batch=batch)\n",
    "update_input_mask(sparsebert)\n",
    "_,_, lm_output_sparse = eval(sparsebert, batch=batch)\n",
    "reset_input_mask(sparsebert)\n",
    "print('Attention MSE, befo softmax', torch.mean(torch.square(lm_output.attentions[-1]-lm_output_sparse.attentions[-1])))\n",
    "set_print(sparsebert, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure input and output mask is same\n",
    "# set_output_masking(sparsebert, True)\n",
    "# reset_input_mask(sparsebert)\n",
    "# eval(sparsebert, batch=batch)\n",
    "# update_input_mask(sparsebert)\n",
    "# ret = eval(sparsebert, batch=batch)\n",
    "# for i in range(3):\n",
    "#     a = sparsebert.encoder.layer[i].attention.self.output_mask\n",
    "#     b = sparsebert.encoder.layer[i+1].attention.self.input_mask\n",
    "#     print(torch.mean(torch.abs(a-b)))\n",
    "# reset_input_mask(sparsebert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3052, -0.0182,  0.4914, -0.5295,  1.0349],\n",
      "        [ 0.1508, -0.2283, -0.1500, -0.2335,  0.7907],\n",
      "        [-0.6254, -0.0668, -0.5428, -0.7241,  1.5681],\n",
      "        [ 0.4267, -0.0869, -0.0414,  0.4975, -1.6607]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.4067, -0.2589,  0.5076, -0.1107,  0.9590],\n",
      "        [-0.1066, -0.5086,  0.3520,  0.1056,  0.3538],\n",
      "        [-1.0309, -0.5523, -0.5106, -0.6852,  2.1186],\n",
      "        [ 0.5187, -0.1235,  0.3521,  1.6831, -1.3839]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([1., 0., 0., 1.], device='cuda:0')\n",
      "tensor([1., 0., 0., 1.], device='cuda:0')\n",
      "tensor([[-0.0822, -0.4312,  0.5096,  0.0294,  1.0529],\n",
      "        [-0.3884, -0.4388,  0.1020,  0.4166,  0.2858],\n",
      "        [-0.8628, -0.5308, -0.6314, -0.2096,  1.2180],\n",
      "        [ 1.0807, -0.3690,  0.1572,  0.9194, -0.5309]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.4568, -0.4038,  0.3431, -0.0683,  0.7169],\n",
      "        [-0.0599, -0.3666,  0.0750,  0.3621, -0.2516],\n",
      "        [-0.3265, -0.7215, -0.8256, -0.4296,  1.4059],\n",
      "        [ 1.9299, -0.0835, -0.6393,  0.4410, -1.0698]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.3052, -0.0182,  0.4914, -0.5295,  1.0349],\n",
      "        [-0.5102,  0.0986,  0.1125, -0.0224,  0.8017],\n",
      "        [-1.0530,  0.4784, -0.7741, -0.4987,  1.3473],\n",
      "        [ 0.4267, -0.0869, -0.0414,  0.4975, -1.6607]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.4067, -0.2589,  0.5076, -0.1107,  0.9590],\n",
      "        [-0.2307, -0.1605,  0.5216,  0.0949,  0.1396],\n",
      "        [-1.2267,  0.4728, -0.5494, -0.6557,  1.7330],\n",
      "        [ 0.5187, -0.1235,  0.3521,  1.6831, -1.3839]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([1., 0., 0., 1.], device='cuda:0')\n",
      "tensor([1., 0., 0., 1.], device='cuda:0')\n",
      "tensor([[-0.0822, -0.4312,  0.5096,  0.0294,  1.0529],\n",
      "        [-0.2188,  0.1564,  0.3835,  0.0084,  0.1328],\n",
      "        [-0.9983,  0.7221, -0.5428, -0.5966,  1.4275],\n",
      "        [ 0.4055,  0.1916,  0.2055,  1.2778, -1.1371]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.4568, -0.4038,  0.3431, -0.0683,  0.7169],\n",
      "        [-0.0630,  0.0976,  0.2362,  0.2903,  0.1388],\n",
      "        [-0.5496,  0.8150, -0.6720, -0.8740,  1.3315],\n",
      "        [ 0.6600,  0.1397, -0.2790,  1.0046, -1.7808]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([1., 0., 0., 0.], device='cuda:0')\n",
      "tensor([1., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "set_print(sparsebert, False)\n",
    "set_masking_timing(sparsebert, 'before_softmax')\n",
    "set_output_masking(sparsebert, False)\n",
    "a = sparse_eval(sparsebert, batch=batch)[-1].hidden_states\n",
    "print(sparsebert.encoder.layer[0].self_attention_outputs[0][0][:4,:5])\n",
    "print(sparsebert.encoder.layer[1].attention.self.last_hidden_states[0,:4,:5])\n",
    "print(sparsebert.encoder.layer[0].attention.self.output_mask[0,:4])\n",
    "print(sparsebert.encoder.layer[1].attention.self.input_mask[0,:4])\n",
    "print(sparsebert.encoder.layer[1].self_attention_outputs[0][0][:4,:5])\n",
    "print(sparsebert.encoder.layer[2].attention.self.last_hidden_states[0,:4,:5])\n",
    "set_output_masking(sparsebert, True)\n",
    "b = sparse_eval(sparsebert, batch=batch)[-1].hidden_states\n",
    "b[-1].shape, torch.mean(torch.abs(a[-1]-b[-1]))\n",
    "b[-1][0][1] # even if i mask output, the result is not 0 because of layernorm? (I am not sure)\n",
    "print(sparsebert.encoder.layer[0].self_attention_outputs[0][0][:4,:5])\n",
    "print(sparsebert.encoder.layer[1].attention.self.last_hidden_states[0,:4,:5])\n",
    "print(sparsebert.encoder.layer[0].attention.self.output_mask[0,:4])\n",
    "print(sparsebert.encoder.layer[1].attention.self.input_mask[0,:4])\n",
    "print(sparsebert.encoder.layer[1].self_attention_outputs[0][0][:4,:5])\n",
    "print(sparsebert.encoder.layer[2].attention.self.last_hidden_states[0,:4,:5])\n",
    "print(sparsebert.encoder.layer[1].attention.self.output_mask[0,:4])\n",
    "print(sparsebert.encoder.layer[2].attention.self.input_mask[0,:4])\n",
    "#sparsebert.encoder.layer[-1].attention.self.output_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approx attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 210156.00it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 211123.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert\n",
      "Trainer.load: Loading...\n"
     ]
    }
   ],
   "source": [
    "from trainer.attention_approx import Trainer as ApproxTrainer\n",
    "approx_trainer = ApproxTrainer(factor=16)\n",
    "approx_trainer.load()\n",
    "approxbert = approx_trainer.bert\n",
    "tbatch = trainer.get_batch(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = -1\n",
    "plot_grid(eval(bert, batch=tbatch)[-1].attentions[L][0,1])\n",
    "plot_grid(eval(approxbert, batch=tbatch, fc=lambda x:x)[-1].attentions[L][0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [01:58<00:00, 12.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9203333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def approx_eval(sparsebert, batch=batch, approxbert=approxbert, ks=[0.5,0.5,0.5,0.5]):\n",
    "    attentions = eval(approxbert, batch=batch, fc=lambda x:x)[-1].attentions\n",
    "    reset_input_mask(sparsebert)\n",
    "    eval(sparsebert, batch=batch)\n",
    "    for i, layer in enumerate(sparsebert.encoder.layer):\n",
    "        assert layer.attention.self.last_attention_probs.shape == attentions[i].shape\n",
    "        layer.attention.self.last_attention_probs = attentions[i]\n",
    "    update_input_mask(sparsebert, ks=ks)\n",
    "    ret = eval(sparsebert, batch=batch)\n",
    "    return ret\n",
    "#approx_eval(sparsebert)[:2]\n",
    "set_print(sparsebert, False)\n",
    "set_masking_timing(sparsebert, 'before_softmax')\n",
    "set_output_masking(sparsebert, True)\n",
    "accuracy(sparsebert, eval=approx_eval, N=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(17., device='cuda:0'), tensor(34, device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = approx_eval(sparsebert)[-1]\n",
    "torch.sum((lm.attentions[0][0,0][0] > 0.0) * 1.0), torch.sum(batch.attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7b3ac0126d0d6fea024471ce24e510948bf6332f7ae1a66cdcb4ee9887514e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
