{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import trainer.glue_base as glue_base\n",
    "import models.sparse_token as sparse\n",
    "import pickle, importlib\n",
    "importlib.reload(glue_base)\n",
    "importlib.reload(sparse)\n",
    "Glue = glue_base.GlueAttentionApproxTrainer\n",
    "PICKLE_PATH = \"glue_benchmark_wiki.pkl\"\n",
    "TEX_PATH = \"saves_plot/glue_benchmark_wiki.tex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer: cola\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f0e04bff3297c11c.arrow\n",
      "Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b9e7d91153cc59cf.arrow\n",
      "Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7e570c95fb4f22e4.arrow\n",
      "Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ea01f5acc0495bfd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "Trainer: Save checkpoint path saves/glue-cola-16-wiki-b5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:01<00:00, 76.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5338774230813111}\n",
      "avg occupy 0.34522852946633237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 42.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.04156136222110997}\n",
      "avg occupy 0.34522852946633237\n",
      "1/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 42.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.25772218156871834}\n",
      "avg occupy 0.34522852946633237\n",
      "2/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 42.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.4197091815697127}\n",
      "avg occupy 0.34522852946633237\n",
      "3/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 42.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.48571743296415204}\n",
      "avg occupy 0.34522852946633237\n",
      "4/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 41.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5162458987125488}\n",
      "avg occupy 0.34522852946633237\n",
      "5/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 42.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5155338105766099}\n",
      "avg occupy 0.34522852946633237\n",
      "6/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5258867890805083}\n",
      "avg occupy 0.34522852946633237\n",
      "7/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 42.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5338774230813111}\n",
      "avg occupy 0.34522852946633237\n",
      "8/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 39.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "9/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 40.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "10/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 41.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "11/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 40.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "12/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 40.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "13/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 40.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "14/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 40.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "15/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 39.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "16/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 131/131 [00:03<00:00, 40.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'matthews_correlation': 0.5311983410233877}\n",
      "avg occupy 0.34522852946633237\n",
      "17/153\n",
      "Trainer: mnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-50a4e6dd970a585c.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-583e5dc11ca81ae7.arrow\n",
      "WARNING:datasets.builder:Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1d54c3b4b02aa479.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ea9dcd50ea1167f5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "\n",
      "WikitextBatchLoader: worker_mainWikitextBatchLoader: worker_main\n",
      "Trainer: Save checkpoint path saves/glue-mnli-16-wiki-b5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:26<00:00, 45.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:30<00:00, 40.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.48099847172694854}\n",
      "avg occupy 0.2057366697815377\n",
      "18/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:31<00:00, 38.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.7674987264391238}\n",
      "avg occupy 0.2057366697815377\n",
      "19/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 35.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8263881813550688}\n",
      "avg occupy 0.2057366697815377\n",
      "20/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:35<00:00, 34.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8371879775853286}\n",
      "avg occupy 0.2057366697815377\n",
      "21/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:37<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8407539480387163}\n",
      "avg occupy 0.2057366697815377\n",
      "22/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:39<00:00, 31.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8415690269994905}\n",
      "avg occupy 0.2057366697815377\n",
      "23/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:41<00:00, 29.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8417727967396842}\n",
      "avg occupy 0.2057366697815377\n",
      "24/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:43<00:00, 28.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "25/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "26/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "27/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 36.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "28/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 35.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "29/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:33<00:00, 36.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "30/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 35.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "31/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:33<00:00, 36.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "32/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "33/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 1227/1227 [00:34<00:00, 35.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8419765664798777}\n",
      "avg occupy 0.2057366697815377\n",
      "34/153\n",
      "Trainer: mrpc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9433d17ba13b5e5f.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a94cfdbaf3fde127.arrow\n",
      "WARNING:datasets.builder:Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7814f5729032a0b8.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1fdda5bad27ee52a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "\n",
      "WikitextBatchLoader: worker_mainWikitextBatchLoader: worker_main\n",
      "Trainer: Save checkpoint path saves/glue-mrpc-16-wiki-b5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:02<00:00, 77.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8440579710144928, 'f1': 0.8865457612821593}\n",
      "avg occupy 0.5399536083129833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.33507246376811595, 'f1': 0.0}\n",
      "avg occupy 0.5399536083129833\n",
      "35/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.3553623188405797, 'f1': 0.08702791461412152}\n",
      "avg occupy 0.5399536083129833\n",
      "36/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:04<00:00, 43.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.4765217391304348, 'f1': 0.403960396039604}\n",
      "avg occupy 0.5399536083129833\n",
      "37/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:04<00:00, 43.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.664927536231884, 'f1': 0.7068965517241379}\n",
      "avg occupy 0.5399536083129833\n",
      "38/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:04<00:00, 43.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8005797101449276, 'f1': 0.8480565371024735}\n",
      "avg occupy 0.5399536083129833\n",
      "39/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:04<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8382608695652174, 'f1': 0.8814279643008927}\n",
      "avg occupy 0.5399536083129833\n",
      "40/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.885605740818911}\n",
      "avg occupy 0.5399536083129833\n",
      "41/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8440579710144928, 'f1': 0.8865457612821593}\n",
      "avg occupy 0.5399536083129833\n",
      "42/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 41.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "43/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "44/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "45/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 41.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "46/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "47/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 41.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "48/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "49/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 41.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "50/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 216/216 [00:05<00:00, 42.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8428985507246377, 'f1': 0.8857022353437368}\n",
      "avg occupy 0.5399536083129833\n",
      "51/153\n",
      "Trainer: qnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2972edcb0068a262.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-37014c01da32f980.arrow\n",
      "WARNING:datasets.builder:Reusing dataset glue (/home/ainl/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7c0b979036415a7d.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ainl/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6d56285c76284a87.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "WikitextBatchLoader: worker_main\n",
      "Trainer: Save checkpoint path saves/glue-qnli-16-wiki-b5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:12<00:00, 53.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.9154310818231741}\n",
      "avg occupy 0.30243502260079336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:17<00:00, 39.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.5680029287937031}\n",
      "avg occupy 0.30243502260079336\n",
      "52/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:17<00:00, 39.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8295808164012447}\n",
      "avg occupy 0.30243502260079336\n",
      "53/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:17<00:00, 38.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8965769723595094}\n",
      "avg occupy 0.30243502260079336\n",
      "54/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:19<00:00, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.9099395936298736}\n",
      "avg occupy 0.30243502260079336\n",
      "55/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:19<00:00, 34.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.9134175361522973}\n",
      "avg occupy 0.30243502260079336\n",
      "56/153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:  66%|██████▌   | 450/683 [00:14<00:07, 30.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ainl/library/discrete_edge_learning/plot_benchmark_glue_wiki.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlai-lab-desk/home/ainl/library/discrete_edge_learning/plot_benchmark_glue_wiki.ipynb#ch0000001vscode-remote?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m ks \u001b[39min\u001b[39;00m kss:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlai-lab-desk/home/ainl/library/discrete_edge_learning/plot_benchmark_glue_wiki.ipynb#ch0000001vscode-remote?line=27'>28</a>\u001b[0m     sparse\u001b[39m.\u001b[39mbenchmark_reset()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmlai-lab-desk/home/ainl/library/discrete_edge_learning/plot_benchmark_glue_wiki.ipynb#ch0000001vscode-remote?line=28'>29</a>\u001b[0m     sparse_score, _ \u001b[39m=\u001b[39m get_score(trainer\u001b[39m.\u001b[39;49meval_sparse_model(ks\u001b[39m=\u001b[39;49mks))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlai-lab-desk/home/ainl/library/discrete_edge_learning/plot_benchmark_glue_wiki.ipynb#ch0000001vscode-remote?line=29'>30</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ks, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m ks\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mdynamic\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlai-lab-desk/home/ainl/library/discrete_edge_learning/plot_benchmark_glue_wiki.ipynb#ch0000001vscode-remote?line=30'>31</a>\u001b[0m         est_k \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mbenchmark_get_average(\u001b[39m'\u001b[39m\u001b[39mest_k\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/library/discrete_edge_learning/trainer/glue_base.py:231\u001b[0m, in \u001b[0;36mGlueAttentionApproxTrainer.eval_sparse_model\u001b[0;34m(self, ks, use_forward)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=227'>228</a>\u001b[0m sparse_cls_bert\u001b[39m.\u001b[39mbert \u001b[39m=\u001b[39m wrapped_bert\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=228'>229</a>\u001b[0m sparse_cls_bert\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=230'>231</a>\u001b[0m sparse_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_base_model(model \u001b[39m=\u001b[39;49m sparse_cls_bert)\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=231'>232</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sparse_result\n",
      "File \u001b[0;32m~/library/discrete_edge_learning/trainer/glue_base.py:182\u001b[0m, in \u001b[0;36mGlueAttentionApproxTrainer.eval_base_model\u001b[0;34m(self, model, amp)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=178'>179</a>\u001b[0m \u001b[39mdel\u001b[39;00m batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=180'>181</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(enabled\u001b[39m=\u001b[39mamp):\n\u001b[0;32m--> <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=181'>182</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch)\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=182'>183</a>\u001b[0m predictions \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/trainer/glue_base.py?line=184'>185</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstsb\u001b[39m\u001b[39m'\u001b[39m: \n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1545\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1536'>1537</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1537'>1538</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1538'>1539</a>\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1539'>1540</a>\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1540'>1541</a>\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1541'>1542</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1542'>1543</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1544'>1545</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1545'>1546</a>\u001b[0m     input_ids,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1546'>1547</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1547'>1548</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1548'>1549</a>\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1549'>1550</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1550'>1551</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1551'>1552</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1552'>1553</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1553'>1554</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1554'>1555</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1556'>1557</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1558'>1559</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/library/discrete_edge_learning/models/sparse_token.py:1090\u001b[0m, in \u001b[0;36mApproxSparseBertModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1087'>1088</a>\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1088'>1089</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_forward_sparse:\n\u001b[0;32m-> <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1089'>1090</a>\u001b[0m     output \u001b[39m=\u001b[39m run_bert_with_approx(\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1090'>1091</a>\u001b[0m         sparse_bert \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse_bert,\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1091'>1092</a>\u001b[0m         approx_bert \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapprox_bert,\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1092'>1093</a>\u001b[0m         input_dict  \u001b[39m=\u001b[39;49m kwargs,\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1093'>1094</a>\u001b[0m         ks          \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mks,\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1094'>1095</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1095'>1096</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1096'>1097</a>\u001b[0m     output \u001b[39m=\u001b[39m run_bert_forward_sparsity(\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1097'>1098</a>\u001b[0m         sparse_bert \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_bert,\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1098'>1099</a>\u001b[0m         input_dict  \u001b[39m=\u001b[39m kwargs,\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1099'>1100</a>\u001b[0m         ks          \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mks,\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1100'>1101</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/library/discrete_edge_learning/models/sparse_token.py:935\u001b[0m, in \u001b[0;36mrun_bert_with_approx\u001b[0;34m(sparse_bert, approx_bert, input_dict, ks)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=932'>933</a>\u001b[0m     attention_input_dict \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(input_dict)\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=933'>934</a>\u001b[0m     attention_input_dict[\u001b[39m'\u001b[39m\u001b[39moutput_attentions\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=934'>935</a>\u001b[0m     ret_approx \u001b[39m=\u001b[39m approx_bert(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mattention_input_dict)\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=935'>936</a>\u001b[0m     attentions \u001b[39m=\u001b[39m ret_approx\u001b[39m.\u001b[39mattentions\n\u001b[1;32m    <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=936'>937</a>\u001b[0m timer_end(\u001b[39m'\u001b[39m\u001b[39meval.approx_att_bert\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/library/discrete_edge_learning/models/sparse_token.py:1061\u001b[0m, in \u001b[0;36mApproxBertModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1059'>1060</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> <a href='file:///home/ainl/library/discrete_edge_learning/models/sparse_token.py?line=1060'>1061</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=986'>987</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=988'>989</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=989'>990</a>\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=990'>991</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=993'>994</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=994'>995</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=995'>996</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=996'>997</a>\u001b[0m     embedding_output,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=997'>998</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=998'>999</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=999'>1000</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1000'>1001</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1001'>1002</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1002'>1003</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1003'>1004</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1004'>1005</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1005'>1006</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1006'>1007</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1007'>1008</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=1008'>1009</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=575'>576</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=576'>577</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=577'>578</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=581'>582</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=582'>583</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=583'>584</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=584'>585</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=585'>586</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=586'>587</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=587'>588</a>\u001b[0m         layer_head_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=588'>589</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=589'>590</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=590'>591</a>\u001b[0m         past_key_value,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=591'>592</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=592'>593</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=594'>595</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=595'>596</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=459'>460</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=460'>461</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=461'>462</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=468'>469</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=469'>470</a>\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=470'>471</a>\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=471'>472</a>\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=472'>473</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=473'>474</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=474'>475</a>\u001b[0m         head_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=475'>476</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=476'>477</a>\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=477'>478</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=478'>479</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=480'>481</a>\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=391'>392</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=392'>393</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=393'>394</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=399'>400</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=400'>401</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=401'>402</a>\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=402'>403</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=403'>404</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=404'>405</a>\u001b[0m         head_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=405'>406</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=406'>407</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=407'>408</a>\u001b[0m         past_key_value,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=408'>409</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=409'>410</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=410'>411</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=411'>412</a>\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:306\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=302'>303</a>\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_layer, value_layer)\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=304'>305</a>\u001b[0m \u001b[39m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=305'>306</a>\u001b[0m attention_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(query_layer, key_layer\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m))\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=307'>308</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key_query\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ainl/anaconda3/envs/torch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py?line=308'>309</a>\u001b[0m     seq_length \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subsets = [\"cola\",\"mnli\",\"mrpc\",\"qnli\",\"qqp\",\"rte\",\"sst2\",\"stsb\",\"wnli\",]\n",
    "kss = [\n",
    "    0.1, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 0.999, 'dynamic', \n",
    "    'dynamic:avg:avg:true', 'dynamic:avg:avg:false', 'dynamic:avg:max:true', 'dynamic:avg:max:false',\n",
    "    'dynamic:max:avg:true', 'dynamic:max:avg:false', 'dynamic:max:max:true', 'dynamic:max:max:false',\n",
    "]\n",
    "kss = ['dynamic']\n",
    "sparse.benchmark_reset()\n",
    "# subsets = [\"mrpc\"]\n",
    "# kss = ['dynamic:avg:avg:f',0.1]\n",
    "\n",
    "def get_score(score):\n",
    "    if 'accuracy' in score:\n",
    "        return score['accuracy'], \"acc\"\n",
    "    first_metric = list(score.keys())[0]\n",
    "    return score[first_metric], first_metric\n",
    "\n",
    "results = {}\n",
    "i = 0\n",
    "for subset in subsets:\n",
    "    trainer = Glue(dataset=subset, factor=16, batch_size=-1, device=0, wiki_train=True)\n",
    "    trainer.load()\n",
    "    scores = {}\n",
    "    metric_name = \"\"\n",
    "    bert_score, metric_name = get_score(trainer.eval_base_model())\n",
    "    scores['bert'] = f'{bert_score:.5f}'\n",
    "    for ks in kss:\n",
    "        sparse.benchmark_reset()\n",
    "        sparse_score, _ = get_score(trainer.eval_sparse_model(ks=ks))\n",
    "        if isinstance(ks, str) and ks.startswith('dynamic'):\n",
    "            est_k = sparse.benchmark_get_average('est_k')\n",
    "            scores[str(ks)] = f'{sparse_score:.5f} (k:{est_k:.2f})'\n",
    "        else:\n",
    "            scores[str(ks)] = f'{sparse_score:.5f}'\n",
    "        i += 1\n",
    "        count = len(subsets) * len(kss)\n",
    "        print(f'{i}/{count}')\n",
    "    results[f\"{subset} ({metric_name})\"] = scores\n",
    "\n",
    "with open(PICKLE_PATH, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "sparse.benchmark_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_159507/610143257.py:54: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  tex = df.to_latex()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cola</th>\n",
       "      <th>mnli</th>\n",
       "      <th>mrpc</th>\n",
       "      <th>qnli</th>\n",
       "      <th>qqp</th>\n",
       "      <th>rte</th>\n",
       "      <th>sst2</th>\n",
       "      <th>stsb</th>\n",
       "      <th>wnli</th>\n",
       "      <th>reproduce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.53388</td>\n",
       "      <td>0.84198</td>\n",
       "      <td>0.84406</td>\n",
       "      <td>0.91543</td>\n",
       "      <td>0.90908</td>\n",
       "      <td>0.72563</td>\n",
       "      <td>0.92431</td>\n",
       "      <td>0.88047</td>\n",
       "      <td>0.56338</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dynamic:original</th>\n",
       "      <td>0.53388 (k:0.48)</td>\n",
       "      <td>0.84004 (k:0.33)</td>\n",
       "      <td>0.83942 (k:0.71)</td>\n",
       "      <td>0.91287 (k:0.44)</td>\n",
       "      <td>0.90920 (k:0.45)</td>\n",
       "      <td>0.72563 (k:0.55)</td>\n",
       "      <td>0.92317 (k:0.73)</td>\n",
       "      <td>0.88043 (k:0.51)</td>\n",
       "      <td>0.56338 (k:0.63)</td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dynamic:w_augment</th>\n",
       "      <td>0.53388 (k:0.48)</td>\n",
       "      <td>0.83647 (k:0.33)</td>\n",
       "      <td>0.83826 (k:0.72)</td>\n",
       "      <td>0.91506 (k:0.48)</td>\n",
       "      <td>0.90905 (k:0.45)</td>\n",
       "      <td>0.66426 (k:0.40)</td>\n",
       "      <td>0.92202 (k:0.68)</td>\n",
       "      <td>0.88034 (k:0.51)</td>\n",
       "      <td>0.56338 (k:0.61)</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dynamic:wo_augment</th>\n",
       "      <td>0.53388 (k:0.48)</td>\n",
       "      <td>0.81559 (k:0.30)</td>\n",
       "      <td>0.74667 (k:0.66)</td>\n",
       "      <td>0.90445 (k:0.41)</td>\n",
       "      <td>0.90893 (k:0.43)</td>\n",
       "      <td>0.70758 (k:0.38)</td>\n",
       "      <td>0.92202 (k:0.69)</td>\n",
       "      <td>0.86572 (k:0.49)</td>\n",
       "      <td>0.56338 (k:0.54)</td>\n",
       "      <td>97.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                cola              mnli              mrpc  \\\n",
       "bert                         0.53388           0.84198           0.84406   \n",
       "dynamic:original    0.53388 (k:0.48)  0.84004 (k:0.33)  0.83942 (k:0.71)   \n",
       "dynamic:w_augment   0.53388 (k:0.48)  0.83647 (k:0.33)  0.83826 (k:0.72)   \n",
       "dynamic:wo_augment  0.53388 (k:0.48)  0.81559 (k:0.30)  0.74667 (k:0.66)   \n",
       "\n",
       "                                qnli               qqp               rte  \\\n",
       "bert                         0.91543           0.90908           0.72563   \n",
       "dynamic:original    0.91287 (k:0.44)  0.90920 (k:0.45)  0.72563 (k:0.55)   \n",
       "dynamic:w_augment   0.91506 (k:0.48)  0.90905 (k:0.45)  0.66426 (k:0.40)   \n",
       "dynamic:wo_augment  0.90445 (k:0.41)  0.90893 (k:0.43)  0.70758 (k:0.38)   \n",
       "\n",
       "                                sst2              stsb              wnli  \\\n",
       "bert                         0.92431           0.88047           0.56338   \n",
       "dynamic:original    0.92317 (k:0.73)  0.88043 (k:0.51)  0.56338 (k:0.63)   \n",
       "dynamic:w_augment   0.92202 (k:0.68)  0.88034 (k:0.51)  0.56338 (k:0.61)   \n",
       "dynamic:wo_augment  0.92202 (k:0.69)  0.86572 (k:0.49)  0.56338 (k:0.54)   \n",
       "\n",
       "                   reproduce  \n",
       "bert                  100.00  \n",
       "dynamic:original       99.87  \n",
       "dynamic:w_augment      98.88  \n",
       "dynamic:wo_augment     97.74  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(PICKLE_PATH, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "with open('glue_benchmark.pkl', 'rb') as f:\n",
    "    results_original = pickle.load(f)\n",
    "\n",
    "def convert_data_to_results(results):\n",
    "    data = []\n",
    "    subsets = list(results.keys())\n",
    "    factors = list(results[subsets[0]].keys())\n",
    "    for factor in factors:             \n",
    "        row = []\n",
    "        for subset in subsets:\n",
    "            row.append(results[subset][factor])\n",
    "        data.append(row)\n",
    "    return data, factors\n",
    "\n",
    "data, factors = convert_data_to_results(results)\n",
    "data_origin, _ = convert_data_to_results(results_original)\n",
    "data_wo_data_augment = (\"0.53388 (k:0.48)\t0.81559 (k:0.30)\t0.74667 (k:0.66)\t0.90445 (k:0.41)\t\"+\\\n",
    "    \"0.90893 (k:0.43)\t0.70758 (k:0.38)\t0.92202 (k:0.69)\t0.86572 (k:0.49)\t0.56338 (k:0.54)\").split(\"\\t\")\n",
    "\n",
    "factors[1] = \"dynamic:w_augment\"\n",
    "indicies = factors+[\"dynamic:original\", \"dynamic:wo_augment\"]\n",
    "columns = subsets[:]\n",
    "df_data = data + [data_origin[9], data_wo_data_augment]\n",
    "\n",
    "#calculate reproducibility\n",
    "data_scalar = []\n",
    "for line in df_data:\n",
    "    xs = []\n",
    "    for item in line:\n",
    "        xs.append(float(item.split()[0]))\n",
    "    data_scalar.append(xs)\n",
    "reproducibilities = []\n",
    "for i in range(len(data_scalar)):\n",
    "    rsum = 0\n",
    "    for k in range(len(data_scalar[i])):\n",
    "        rsum += data_scalar[i][k]/data_scalar[0][k]\n",
    "    rsum /= len(data_scalar[i])\n",
    "    reproducibilities.append(rsum)\n",
    "for i, r in enumerate(reproducibilities):\n",
    "    df_data[i].append(f\"{r*100:.2f}\")\n",
    "columns.append(\"reproduce\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    df_data,\n",
    "    columns=columns, \n",
    "    index=indicies\n",
    ")\n",
    "df = df.reindex([\"bert\", \"dynamic:original\", \"dynamic:w_augment\", \"dynamic:wo_augment\"])\n",
    "tex = df.to_latex()\n",
    "with open(TEX_PATH, 'w') as f:\n",
    "    f.write(tex)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre data augment\n",
    "\n",
    "cola (matthews_correlation)\tmnli (acc)\tmrpc (acc)\tqnli (acc)\tqqp (acc)\trte (acc)\tsst2 (acc)\tstsb (pearson)\twnli (acc)\n",
    "\n",
    "bert\t0.53388\t0.84198\t0.84406\t0.91543\t0.90908\t0.72563\t0.92431\t0.88047\t0.56338\n",
    "\n",
    "dynamic\t0.53388 (k:0.48)\t0.81559 (k:0.30)\t0.74667 (k:0.66)\t0.90445 (k:0.41)\t0.90893 (k:0.43)\t0.70758 (k:0.38)\t0.92202 (k:0.69)\t0.86572 (k:0.49)\t0.56338 (k:0.54)\n",
    "\n",
    "dynamic:original\t0.53388 (k:0.48)\t0.84004 (k:0.33)\t0.83942 (k:0.71)\t0.91287 (k:0.44)\t0.90920 (k:0.45)\t0.72563 (k:0.55)\t0.92317 (k:0.73)\t0.88043 (k:0.51)\t0.56338 (k:0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7b3ac0126d0d6fea024471ce24e510948bf6332f7ae1a66cdcb4ee9887514e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
