{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer.glue_base as glue_base\n",
    "import models.sparse_token as sparse\n",
    "import pickle, importlib\n",
    "importlib.reload(glue_base)\n",
    "importlib.reload(sparse)\n",
    "Glue = glue_base.GlueAttentionApproxTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer: mrpc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-7ab73b41110526b8.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-77eb4a03ea1c3167.arrow\n",
      "Reusing dataset glue (C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-c3b7ac3527887b23.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-043d9930749d30f0.arrow\n",
      "eval: 100%|██████████| 216/216 [00:04<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.8440579710144928, 'f1': 0.8865457612821593}\n",
      "avg occupy 0.5399536083129833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:   0%|          | 0/216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg avg False\n",
      "avg avg False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval:   0%|          | 0/216 [00:43<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e20dc3345c5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbenchmark_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0msparse_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_sparse_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dynamic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mest_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbenchmark_get_average\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'est_k'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Library\\discrete_edge_learning\\trainer\\glue_base.py\u001b[0m in \u001b[0;36meval_sparse_model\u001b[1;34m(self, ks)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0msparse_cls_bert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msparse_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_base_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse_cls_bert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msparse_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Library\\discrete_edge_learning\\trainer\\glue_base.py\u001b[0m in \u001b[0;36meval_base_model\u001b[1;34m(self, model, amp)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1545\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1546\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Library\\discrete_edge_learning\\models\\sparse_token.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1009\u001b[1;33m         output = run_bert_with_approx(\n\u001b[0m\u001b[0;32m   1010\u001b[0m             \u001b[0msparse_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_bert\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[0mapprox_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapprox_bert\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Library\\discrete_edge_learning\\models\\sparse_token.py\u001b[0m in \u001b[0;36mrun_bert_with_approx\u001b[1;34m(sparse_bert, approx_bert, input_dict, ks)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m     \u001b[0mtimer_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval.update_mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mupdate_input_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_bert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[0mtimer_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval.update_mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Library\\discrete_edge_learning\\models\\sparse_token.py\u001b[0m in \u001b[0;36mupdate_input_mask\u001b[1;34m(sparse_bert, ks)\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_unsqueeze\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_unsqueeze\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m             mask, indices, impacts = layer.attention.self.update_input_mask_from_previous_attention(\n\u001b[0m\u001b[0;32m    899\u001b[0m                 \u001b[0moutput_token_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m                 \u001b[0moutput_token_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Library\\discrete_edge_learning\\models\\sparse_token.py\u001b[0m in \u001b[0;36mupdate_input_mask_from_previous_attention\u001b[1;34m(self, output_token_mask, output_token_indices, output_token_impact, k)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_input_mask_from_previous_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_token_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_token_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_token_impact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         input_mask, input_indices, input_impacts = update_input_mask_from_previous_attention(\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_attention_probs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Library\\discrete_edge_learning\\models\\sparse_token.py\u001b[0m in \u001b[0;36mupdate_input_mask_from_previous_attention\u001b[1;34m(attention_mask, previous_attention, output_token_indices, output_token_impact, head_reduce_method, token_reduce_method, apply_token_impact, k, k_estimate)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mapply_token_impact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_token_impact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'true'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_reduce_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_reduce_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_token_impact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'unknown method {k}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m             )\n\u001b[1;32m--> 848\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "subsets = [\"cola\",\"mnli\",\"mrpc\",\"qnli\",\"qqp\",\"rte\",\"sst2\",\"stsb\",\"wnli\",]\n",
    "kss = [\n",
    "    0.1, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 0.999, 'dynamic', \n",
    "    'dynamic:avg:avg:true', 'dynamic:avg:avg:false', 'dynamic:avg:max:true', 'dynamic:avg:max:false',\n",
    "    'dynamic:max:avg:true', 'dynamic:max:avg:false', 'dynamic:max:max:true', 'dynamic:max:max:false',\n",
    "]\n",
    "sparse.benchmark_reset()\n",
    "# subsets = [\"mrpc\"]\n",
    "# kss = ['dynamic:avg:avg:f',0.1]\n",
    "\n",
    "def get_score(score):\n",
    "    if 'accuracy' in score:\n",
    "        return score['accuracy'], \"acc\"\n",
    "    first_metric = list(score.keys())[0]\n",
    "    return score[first_metric], first_metric\n",
    "\n",
    "results = {}\n",
    "i = 0\n",
    "for subset in subsets:\n",
    "    trainer = Glue(dataset=subset, factor=16, batch_size=-1, device=0)\n",
    "    trainer.load()\n",
    "    scores = {}\n",
    "    metric_name = \"\"\n",
    "    bert_score, metric_name = get_score(trainer.eval_base_model())\n",
    "    scores['bert'] = f'{bert_score:.5f}'\n",
    "    for ks in kss:\n",
    "        sparse.benchmark_reset()\n",
    "        sparse_score, _ = get_score(trainer.eval_sparse_model(ks=ks))\n",
    "        if isinstace(ks, str) and ks.startswith('dynamic'):\n",
    "            est_k = sparse.benchmark_get_average('est_k')\n",
    "            scores[str(ks)] = f'{sparse_score:.5f} (k:{est_k:.2f})'\n",
    "        else:\n",
    "            scores[str(ks)] = f'{sparse_score:.5f}'\n",
    "        i += 1\n",
    "        count = len(subsets) * len(kss)\n",
    "        print(f'{i}/{count}')\n",
    "    results[f\"{subset} ({metric_name})\"] = scores\n",
    "\n",
    "with open('glue_benchmark.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "sparse.benchmark_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cola (matthews_correlation)</th>\n",
       "      <th>mnli (acc)</th>\n",
       "      <th>mrpc (acc)</th>\n",
       "      <th>qnli (acc)</th>\n",
       "      <th>qqp (acc)</th>\n",
       "      <th>rte (acc)</th>\n",
       "      <th>sst2 (acc)</th>\n",
       "      <th>stsb (pearson)</th>\n",
       "      <th>wnli (acc)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.53388</td>\n",
       "      <td>0.84208</td>\n",
       "      <td>0.84406</td>\n",
       "      <td>0.91543</td>\n",
       "      <td>0.90908</td>\n",
       "      <td>0.72563</td>\n",
       "      <td>0.92431</td>\n",
       "      <td>0.88046</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.00800</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.33507</td>\n",
       "      <td>0.59967</td>\n",
       "      <td>0.72602</td>\n",
       "      <td>0.49819</td>\n",
       "      <td>0.69381</td>\n",
       "      <td>0.18832</td>\n",
       "      <td>0.60563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.32926</td>\n",
       "      <td>0.81518</td>\n",
       "      <td>0.35768</td>\n",
       "      <td>0.84185</td>\n",
       "      <td>0.89043</td>\n",
       "      <td>0.68592</td>\n",
       "      <td>0.83486</td>\n",
       "      <td>0.62689</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.375</th>\n",
       "      <td>0.45462</td>\n",
       "      <td>0.83780</td>\n",
       "      <td>0.50899</td>\n",
       "      <td>0.90079</td>\n",
       "      <td>0.90628</td>\n",
       "      <td>0.71841</td>\n",
       "      <td>0.88073</td>\n",
       "      <td>0.77045</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.48454</td>\n",
       "      <td>0.84137</td>\n",
       "      <td>0.70957</td>\n",
       "      <td>0.91232</td>\n",
       "      <td>0.90878</td>\n",
       "      <td>0.73285</td>\n",
       "      <td>0.90367</td>\n",
       "      <td>0.84864</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.625</th>\n",
       "      <td>0.50845</td>\n",
       "      <td>0.84208</td>\n",
       "      <td>0.81565</td>\n",
       "      <td>0.91470</td>\n",
       "      <td>0.90910</td>\n",
       "      <td>0.72202</td>\n",
       "      <td>0.92087</td>\n",
       "      <td>0.87315</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.52069</td>\n",
       "      <td>0.84218</td>\n",
       "      <td>0.84058</td>\n",
       "      <td>0.91543</td>\n",
       "      <td>0.90910</td>\n",
       "      <td>0.72563</td>\n",
       "      <td>0.92317</td>\n",
       "      <td>0.87936</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.875</th>\n",
       "      <td>0.53388</td>\n",
       "      <td>0.84218</td>\n",
       "      <td>0.84406</td>\n",
       "      <td>0.91543</td>\n",
       "      <td>0.90905</td>\n",
       "      <td>0.72563</td>\n",
       "      <td>0.92317</td>\n",
       "      <td>0.88040</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.53388</td>\n",
       "      <td>0.84208</td>\n",
       "      <td>0.84406</td>\n",
       "      <td>0.91543</td>\n",
       "      <td>0.90908</td>\n",
       "      <td>0.72563</td>\n",
       "      <td>0.92431</td>\n",
       "      <td>0.88046</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dynamic</th>\n",
       "      <td>0.53388 (k:0.48)</td>\n",
       "      <td>0.84004 (k:0.33)</td>\n",
       "      <td>0.83942 (k:0.71)</td>\n",
       "      <td>0.91287 (k:0.44)</td>\n",
       "      <td>0.90920 (k:0.45)</td>\n",
       "      <td>0.72563 (k:0.55)</td>\n",
       "      <td>0.92317 (k:0.73)</td>\n",
       "      <td>0.88043 (k:0.51)</td>\n",
       "      <td>0.56338 (k:0.63)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cola (matthews_correlation)        mnli (acc)        mrpc (acc)  \\\n",
       "bert                        0.53388           0.84208           0.84406   \n",
       "0.1                         0.00800           0.59042           0.33507   \n",
       "0.25                        0.32926           0.81518           0.35768   \n",
       "0.375                       0.45462           0.83780           0.50899   \n",
       "0.5                         0.48454           0.84137           0.70957   \n",
       "0.625                       0.50845           0.84208           0.81565   \n",
       "0.75                        0.52069           0.84218           0.84058   \n",
       "0.875                       0.53388           0.84218           0.84406   \n",
       "0.999                       0.53388           0.84208           0.84406   \n",
       "dynamic            0.53388 (k:0.48)  0.84004 (k:0.33)  0.83942 (k:0.71)   \n",
       "\n",
       "               qnli (acc)         qqp (acc)         rte (acc)  \\\n",
       "bert              0.91543           0.90908           0.72563   \n",
       "0.1               0.59967           0.72602           0.49819   \n",
       "0.25              0.84185           0.89043           0.68592   \n",
       "0.375             0.90079           0.90628           0.71841   \n",
       "0.5               0.91232           0.90878           0.73285   \n",
       "0.625             0.91470           0.90910           0.72202   \n",
       "0.75              0.91543           0.90910           0.72563   \n",
       "0.875             0.91543           0.90905           0.72563   \n",
       "0.999             0.91543           0.90908           0.72563   \n",
       "dynamic  0.91287 (k:0.44)  0.90920 (k:0.45)  0.72563 (k:0.55)   \n",
       "\n",
       "               sst2 (acc)    stsb (pearson)        wnli (acc)  \n",
       "bert              0.92431           0.88046           0.56338  \n",
       "0.1               0.69381           0.18832           0.60563  \n",
       "0.25              0.83486           0.62689           0.56338  \n",
       "0.375             0.88073           0.77045           0.56338  \n",
       "0.5               0.90367           0.84864           0.56338  \n",
       "0.625             0.92087           0.87315           0.56338  \n",
       "0.75              0.92317           0.87936           0.56338  \n",
       "0.875             0.92317           0.88040           0.56338  \n",
       "0.999             0.92431           0.88046           0.56338  \n",
       "dynamic  0.92317 (k:0.73)  0.88043 (k:0.51)  0.56338 (k:0.63)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('glue_benchmark.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "data = []\n",
    "subsets = list(results.keys())\n",
    "factors = list(results[subsets[0]].keys())\n",
    "for factor in factors:\n",
    "    row = []\n",
    "    for subset in subsets:\n",
    "        row.append(results[subset][factor])\n",
    "    data.append(row)\n",
    "pd.DataFrame(data, columns=subsets, index=factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer: qnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-95cdbfccba10767f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-a121d057d8b0504c.arrow\n",
      "Reusing dataset glue (C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-81af1b1d0da19e67.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AinL\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-efc6aadc78835551.arrow\n"
     ]
    }
   ],
   "source": [
    "trainer = Glue(dataset='qnli', factor=16, batch_size=-1, device=0)\n",
    "trainer.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:25<00:00, 26.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.9154310818231741}\n",
      "avg occupy 0.30243502260079336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9154310818231741}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.bert = trainer.model_bert\n",
    "trainer.eval_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 683/683 [00:36<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric score {'accuracy': 0.5996705107084019}\n",
      "avg occupy 0.30243502260079336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5996705107084019}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.seed()\n",
    "import models.sparse_token as sparse\n",
    "import transformers.models.bert.modeling_bert as berts\n",
    "import importlib\n",
    "importlib.reload(sparse)\n",
    "\n",
    "wrapped_bert = sparse.ApproxSparseBertModel(trainer.model_bert, approx_bert=trainer.approx_bert, ks=0.1)\n",
    "sparse_cls_bert = berts.BertForSequenceClassification(trainer.model_bert.config)\n",
    "sparse_cls_bert.load_state_dict(trainer.model.state_dict())\n",
    "sparse_cls_bert.bert = wrapped_bert\n",
    "sparse_cls_bert.to(trainer.device).eval()\n",
    "\n",
    "trainer.eval_base_model(model = sparse_cls_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7b3ac0126d0d6fea024471ce24e510948bf6332f7ae1a66cdcb4ee9887514e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
