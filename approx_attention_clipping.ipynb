{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, math, time, sys, os, tqdm\n",
    "import numpy as np\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 210894.80it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 217139.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert-mini\n",
      "Trainer.load: Loading... saves/cls_bert-mini.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 212387.93it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 205400.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert-mini\n",
      "Trainer.load: Loading... saves/cls_bert-mini.pth\n",
      "Trainer.load: saves/att_approx_16_bert-mini.pth\n",
      "approx trained 37500\n"
     ]
    }
   ],
   "source": [
    "from trainer.classification import Trainer\n",
    "from trainer.attention_approx import Trainer as ApproxTrainer\n",
    "batch_size = 4\n",
    "device = 1\n",
    "factor = 16\n",
    "\n",
    "trainer = Trainer(batch_size=batch_size, model='bert-mini', device=device)\n",
    "trainer.load()\n",
    "trainer.model.eval()\n",
    "bert = trainer.model.bert\n",
    "fc = trainer.model.classifier\n",
    "batch = trainer.get_batch()\n",
    "test_batch = trainer.get_batch(test=False)\n",
    "\n",
    "approx_trainer = ApproxTrainer(batch_size=batch_size, factor=factor, model=trainer.model_type, device=trainer.device)\n",
    "approx_trainer.load()\n",
    "approx_bert = approx_trainer.bert\n",
    "approx_bert = approx_bert.eval()\n",
    "print('approx trained', approx_trainer.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.sparse_token' from 'f:\\\\Library\\\\discrete_edge_learning\\\\models\\\\sparse_token.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import models.sparse_token as sparse\n",
    "importlib.reload(sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(trainer.device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([1, 2, 4, 1], device='cuda:1'),\n",
       "  tensor([1, 2, 4, 1], device='cuda:1')),\n",
       " (tensor([1, 2, 4, 1], device='cuda:1'),\n",
       "  tensor([1, 2, 4, 1], device='cuda:1')))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_fc(lm_output, fc=fc, batch=batch):\n",
    "    last_hidden = lm_output.last_hidden_state[:,0,:]\n",
    "    x = fc(last_hidden)\n",
    "    return torch.argmax(x, dim=-1), batch.labels, lm_output\n",
    "\n",
    "def eval(bert, fc=fc, batch=batch):\n",
    "    lm_output = bert(\n",
    "        input_ids = batch.input_ids, \n",
    "        attention_mask = batch.attention_masks,\n",
    "        output_hidden_states = True,\n",
    "        output_attentions = True,\n",
    "    )\n",
    "    return eval_fc(lm_output, fc=fc, batch=batch)\n",
    "\n",
    "def approx_eval(sparse_bert, approx_bert, fc=fc, batch=batch):\n",
    "    lm_output = sparse.run_bert_with_approx(\n",
    "        sparse_bert, \n",
    "        approx_bert, \n",
    "        {\n",
    "            'input_ids': batch.input_ids,\n",
    "            'attention_mask': batch.attention_masks,\n",
    "            'output_hidden_states': True,\n",
    "            'output_attentions': True,\n",
    "        },\n",
    "        ks = [0.25]*len(sparse_bert.encoder.layer),\n",
    "    )\n",
    "    return eval_fc(lm_output, fc=fc, batch=batch)\n",
    "    \n",
    "eval(bert)[:2], approx_eval(sparse_bert, approx_bert)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:07<00:00, 60.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_att                   : 0:00:02.331907 (18.73%)\n",
      "approx_mask_reset            : 0:00:00.099975 (0.80%)\n",
      "approx_mask_reset_inverse    : 0:00:00.040986 (0.33%)\n",
      "approx_mask_update           : 0:00:00.557000 (4.47%)\n",
      "approx_sparse                : 0:00:03.497006 (28.09%)\n",
      "bert.attention.output        : 0:00:00.483997 (3.89%)\n",
      "bert.attention.probs.dropout : 0:00:00.026012 (0.21%)\n",
      "bert.attention.qkv           : 0:00:00.974982 (7.83%)\n",
      "bert.attention.scores.matmul : 0:00:00.171028 (1.37%)\n",
      "bert.intermediate            : 0:00:00.371982 (2.99%)\n",
      "bert.output                  : 0:00:00.457013 (3.67%)\n",
      "sparselinear                 : 0:00:01.751020 (14.07%)\n",
      "sparselinear.gather          : 0:00:00.440955 (3.54%)\n",
      "sparselinear.linear          : 0:00:00.577010 (4.64%)\n",
      "sparselinear.scatter_        : 0:00:00.667049 (5.36%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9106578947368421, 0.9106578947368421, False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(sparse)\n",
    "sparse.benchmark_reset()\n",
    "sparse.timer_reset()\n",
    "\n",
    "def accuracy(batch_eval, N=7600//16, return_lm=False):\n",
    "    #N = 10\n",
    "    trainer.seed()\n",
    "    trainer.dataset.batch_size = 16\n",
    "    acc_sum = 0\n",
    "    for i in tqdm.tqdm(range(N)):\n",
    "        batch = trainer.get_batch(test=True)\n",
    "        with torch.no_grad():\n",
    "            output, label, _ = batch_eval(batch)\n",
    "        acc_sum += torch.mean((output == label) * 1.0)\n",
    "    if return_lm: return acc_sum.item() / N, _\n",
    "    return acc_sum.item() / N\n",
    "\n",
    "# setup for evaluation\n",
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(trainer.device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse_bert = sparse_bert.to(trainer.device)\n",
    "approx_bert = approx_bert.to(trainer.device)\n",
    "bert = bert.to(trainer.device)\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse.timer_reset()\n",
    "acc_approx, lm = accuracy(\n",
    "    lambda batch: approx_eval(sparse_bert, approx_bert, batch=batch),\n",
    "    return_lm = True,\n",
    ")\n",
    "acc_bert = acc_approx\n",
    "#acc_bert = accuracy(lambda batch: eval(bert, batch=batch))\n",
    "sparse.timer_report()\n",
    "sparse.benchmark_report()\n",
    "acc_bert, acc_approx, abs(acc_approx - 0.9236111111111112) < 0.001\n",
    "\n",
    "#bert-mini 4 0.25\n",
    "#sum, sum = 0.9217105263157894\n",
    "#sum, max = 0.9236842105263158\n",
    "#max, sum = 0.9223684210526316\n",
    "#max, max = 0.9221052631578948\n",
    "#no token impact = 0.9239473684210526 V\n",
    "\n",
    "#bert-mini 8 0.25\n",
    "#sum, sum = 0.9178947368421052 V\n",
    "#sum, max = 0.9111842105263158\n",
    "#max, sum = 0.9157894736842105\n",
    "#max, max = 0.9102631578947369\n",
    "#no token impact = 0.9146052631578947\n",
    "\n",
    "#bert-mini 16 0.25\n",
    "#sum, sum = 0.910921052631579\n",
    "#sum, max = 0.91\n",
    "#max, sum = 0.9134210526315789 V\n",
    "#max, max = 0.9117105263157895\n",
    "#no token impact = 0.9106578947368421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4932e-02, 5.0272e-02, 2.7836e-04, 4.4579e-04, 1.7111e-01, 9.5864e-03,\n",
      "         5.2950e-03],\n",
      "        [1.3638e-01, 2.0278e-01, 5.4214e-04, 2.3688e-05, 1.4050e-03, 1.0286e-03,\n",
      "         1.7702e-03]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_grid(grid):\n",
    "    plt.imshow(grid.cpu().detach().numpy())\n",
    "    #plt.colorbar()\n",
    "    plt.show()\n",
    "plot_grid(lm.attentions[-4][0][0][:50, :50])\n",
    "print(lm.attentions[-2][0][0][:2, :7])\n",
    "#tensor([[0.0246, 0.0012, 0.0206, 0.0003, 0.0000, 0.0002, 0.0049]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(eval, batch_size=8, N=100, WARM=20, amp=False, device=trainer.device, end_warm=None):\n",
    "    assert WARM < (N * 0.33)\n",
    "    trainer.dataset.batch_size = batch_size\n",
    "    batch = trainer.get_batch(test=True)\n",
    "    batch = batch.to(device)\n",
    "    assert batch.input_ids.shape[0] == batch_size\n",
    "    for i in tqdm.tqdm(range(N)):\n",
    "        if i == WARM: \n",
    "            t = time.time()\n",
    "            if not end_warm is None: end_warm()\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=amp):\n",
    "            eval(batch)\n",
    "    t = time.time() - t\n",
    "    t_item = t / (batch_size * (N-WARM))\n",
    "    return t, t_item * 1000, 1.0/t_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_att                   : 0:00:00.953405 (18.38%)\n",
      "approx_mask_reset            : 0:00:00 (0.00%)\n",
      "approx_mask_reset_inverse    : 0:00:00 (0.00%)\n",
      "approx_mask_update           : 0:00:00.328132 (6.33%)\n",
      "approx_sparse                : 0:00:01.421596 (27.40%)\n",
      "bert.attention.output        : 0:00:00.124890 (2.41%)\n",
      "bert.attention.probs.dropout : 0:00:00 (0.00%)\n",
      "bert.attention.qkv           : 0:00:00.343886 (6.63%)\n",
      "bert.attention.scores.matmul : 0:00:00.046874 (0.90%)\n",
      "bert.intermediate            : 0:00:00.171860 (3.31%)\n",
      "bert.output                  : 0:00:00.296903 (5.72%)\n",
      "sparselinear                 : 0:00:00.750029 (14.46%)\n",
      "sparselinear.gather          : 0:00:00.124923 (2.41%)\n",
      "sparselinear.linear          : 0:00:00.281133 (5.42%)\n",
      "sparselinear.scatter_        : 0:00:00.343973 (6.63%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.703131914138794, 0.9599190036004239, 1041.7545608006947)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(sparse)\n",
    "sparse.timer_reset()\n",
    "benchmark_device = 'cuda'\n",
    "benchmark_batch_size = 128\n",
    "\n",
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(benchmark_device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse_bert=sparse_bert.to(benchmark_device)\n",
    "approx_bert=approx_bert.to(benchmark_device)\n",
    "time_approx = benchmark(\n",
    "    eval = lambda batch: approx_eval(sparse_bert, approx_bert, batch=batch, fc=lambda x: x),\n",
    "    batch_size = benchmark_batch_size,\n",
    "    WARM = 3,\n",
    "    N = 25,\n",
    "    device = benchmark_device,\n",
    "    end_warm = lambda: sparse.timer_reset()\n",
    ")\n",
    "sparse.timer_report()\n",
    "time_approx\n",
    "\n",
    "# bert.attention.output        : 0:00:00.545988 (3.04%)\n",
    "# bert.attention.probs.dropout : 0:00:00.006996 (0.04%)\n",
    "# bert.attention.qkv           : 0:00:01.473990 (8.20%)\n",
    "# bert.attention.scores.matmul : 0:00:00.113033 (0.63%)\n",
    "# bert.intermediate            : 0:00:02.113082 (11.75%)\n",
    "# bert.output                  : 0:00:01.848977 (10.28%)\n",
    "# sparselinear.linear          : 0:00:03.801073 (21.14%)\n",
    "\n",
    "# bert.attention.output        : 0:00:01.103962 (2.75%)\n",
    "# bert.attention.probs.dropout : 0:00:00.010004 (0.02%)\n",
    "# bert.attention.qkv           : 0:00:02.440944 (6.07%)\n",
    "# bert.attention.scores.matmul : 0:00:00.534112 (1.33%)\n",
    "# bert.intermediate            : 0:00:02.811061 (6.99%)\n",
    "# bert.output                  : 0:00:02.548062 (6.34%)\n",
    "# sparselinear                 : 0:00:07.770034 (19.33%)\n",
    "# sparselinear.gather          : 0:00:01.343004 (3.34%)\n",
    "# sparselinear.linear          : 0:00:04.463333 (11.11%)\n",
    "# sparselinear.scatter_        : 0:00:01.947706 (4.85%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 18.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.343578815460205, 0.4771231588992205, 2095.8949096227443)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = bert.to(benchmark_device)\n",
    "time_bert = benchmark(\n",
    "    lambda batch: eval(bert, batch=batch, fc=lambda x: x), \n",
    "    batch_size = benchmark_batch_size,\n",
    "    WARM = 3,\n",
    "    N=25,\n",
    "    device = benchmark_device\n",
    ")\n",
    "time_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2).unsqueeze(-1).repeat(1, 1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLayer(\n",
       "  (attention): BertAttention(\n",
       "    (self): BertSelfAttention(\n",
       "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (LayerNorm): LayerNorm((96,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): BertIntermediate(\n",
       "    (dense): Linear(in_features=96, out_features=3072, bias=True)\n",
       "  )\n",
       "  (output): BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=96, bias=True)\n",
       "    (LayerNorm): LayerNorm((96,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_bert.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7b3ac0126d0d6fea024471ce24e510948bf6332f7ae1a66cdcb4ee9887514e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
