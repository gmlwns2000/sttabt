{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, math, time, sys, os, tqdm\n",
    "import numpy as np\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 211638.02it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 211104.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert-base\n",
      "Trainer.load: Loading... saves/cls_bert-base.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 214283.46it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 211113.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-12_H-768_A-12 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert-base\n",
      "Trainer.load: Loading... saves/cls_bert-base.pth\n",
      "Trainer.load: saves/att_approx_16_bert-base.pth\n"
     ]
    }
   ],
   "source": [
    "from trainer.classification import Trainer\n",
    "from trainer.attention_approx import Trainer as ApproxTrainer\n",
    "batch_size = 8\n",
    "\n",
    "trainer = Trainer(batch_size=batch_size, model='bert-base')\n",
    "trainer.load()\n",
    "trainer.model.eval()\n",
    "bert = trainer.model.bert\n",
    "fc = trainer.model.classifier\n",
    "batch = trainer.get_batch()\n",
    "test_batch = trainer.get_batch(test=False)\n",
    "\n",
    "approx_trainer = ApproxTrainer(batch_size=batch_size, factor=16, model=trainer.model_type)\n",
    "approx_trainer.load()\n",
    "approx_bert = approx_trainer.bert\n",
    "approx_bert = approx_bert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.sparse_token' from 'f:\\\\Library\\\\discrete_edge_learning\\\\models\\\\sparse_token.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import models.sparse_token as sparse\n",
    "importlib.reload(sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(trainer.device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([8, 71]), attention_scores:torch.Size([8, 12, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([1, 2, 4, 1, 3, 4, 3, 3], device='cuda:0'),\n",
       "  tensor([1, 2, 4, 1, 3, 4, 3, 3], device='cuda:0')),\n",
       " (tensor([1, 1, 1, 1, 1, 1, 3, 1], device='cuda:0'),\n",
       "  tensor([1, 2, 4, 1, 3, 4, 3, 3], device='cuda:0')))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_fc(lm_output, fc=fc, batch=batch):\n",
    "    last_hidden = lm_output.last_hidden_state[:,0,:]\n",
    "    x = fc(last_hidden)\n",
    "    return torch.argmax(x, dim=-1), batch.labels, lm_output\n",
    "\n",
    "def eval(bert, fc=fc, batch=batch):\n",
    "    lm_output = bert(\n",
    "        input_ids = batch.input_ids, \n",
    "        attention_mask = batch.attention_masks,\n",
    "        output_hidden_states = True,\n",
    "        output_attentions = True,\n",
    "    )\n",
    "    return eval_fc(lm_output, fc=fc, batch=batch)\n",
    "\n",
    "def approx_eval(sparse_bert, approx_bert, fc=fc, batch=batch):\n",
    "    lm_output = sparse.run_bert_with_approx(\n",
    "        sparse_bert, \n",
    "        approx_bert, \n",
    "        {\n",
    "            'input_ids': batch.input_ids,\n",
    "            'attention_mask': batch.attention_masks,\n",
    "            'output_hidden_states': True,\n",
    "            'output_attentions': True,\n",
    "        },\n",
    "        ks = [0.1]*12, #[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.35,0.35,0.15,],\n",
    "    )\n",
    "    return eval_fc(lm_output, fc=fc, batch=batch)\n",
    "    \n",
    "eval(bert)[:2], approx_eval(sparse_bert, approx_bert)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:02<00:00, 20.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_att                   : 0:00:00.617962 (15.21%)\n",
      "approx_mask_reset            : 0:00:00.016999 (0.42%)\n",
      "approx_mask_reset_inverse    : 0:00:00.005999 (0.15%)\n",
      "approx_mask_update           : 0:00:00.193018 (4.75%)\n",
      "approx_sparse                : 0:00:01.109999 (27.31%)\n",
      "bert.attention.output        : 0:00:00.176001 (4.33%)\n",
      "bert.attention.probs.dropout : 0:00:00.009991 (0.25%)\n",
      "bert.attention.qkv           : 0:00:00.351984 (8.66%)\n",
      "bert.attention.scores.matmul : 0:00:00.081976 (2.02%)\n",
      "bert.intermediate            : 0:00:00.143981 (3.54%)\n",
      "bert.output                  : 0:00:00.119043 (2.93%)\n",
      "sparselinear                 : 0:00:00.629024 (15.48%)\n",
      "sparselinear.gather          : 0:00:00.127008 (3.13%)\n",
      "sparselinear.linear          : 0:00:00.310005 (7.63%)\n",
      "sparselinear.scatter_        : 0:00:00.171008 (4.21%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3680555555555556, 0.3680555555555556, False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(sparse)\n",
    "def accuracy(batch_eval, N=720//16):\n",
    "    trainer.seed()\n",
    "    trainer.dataset.batch_size = 16\n",
    "    acc_sum = 0\n",
    "    for i in tqdm.tqdm(range(N)):\n",
    "        batch = trainer.get_batch(test=True)\n",
    "        with torch.no_grad():\n",
    "            output, label, _ = batch_eval(batch)\n",
    "        acc_sum += torch.mean((output == label) * 1.0)\n",
    "    return acc_sum.item() / N\n",
    "\n",
    "# setup for evaluation\n",
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(trainer.device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse_bert = sparse_bert.to(trainer.device)\n",
    "approx_bert = approx_bert.to(trainer.device)\n",
    "bert = bert.to(trainer.device)\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse.timer_reset()\n",
    "acc_bert = acc_approx = accuracy(lambda batch: approx_eval(sparse_bert, approx_bert, batch=batch))\n",
    "#acc_bert = accuracy(lambda batch: eval(bert, batch=batch))\n",
    "sparse.timer_report()\n",
    "acc_bert, acc_approx, abs(acc_approx - 0.93046875) < 0.001\n",
    "#(0.934375, 0.92203125)\n",
    "#(0.934375, 0.93359375)\n",
    "# 0.8486328125\n",
    "\n",
    "#(0.9243055555555556, 0.9173611111111111, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(eval, batch_size=8, N=100, WARM=20, amp=False, device=trainer.device, end_warm=None):\n",
    "    assert WARM < (N * 0.33)\n",
    "    trainer.dataset.batch_size = batch_size\n",
    "    batch = trainer.get_batch(test=True)\n",
    "    batch = batch.to(device)\n",
    "    assert batch.input_ids.shape[0] == batch_size\n",
    "    for i in tqdm.tqdm(range(N)):\n",
    "        if i == WARM: \n",
    "            t = time.time()\n",
    "            if not end_warm is None: end_warm()\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=amp):\n",
    "            eval(batch)\n",
    "    t = time.time() - t\n",
    "    t_item = t / (batch_size * (N-WARM))\n",
    "    return t, t_item * 1000, 1.0/t_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_att                   : 0:00:00.530008 (16.51%)\n",
      "approx_mask_reset            : 0:00:00.009992 (0.31%)\n",
      "approx_mask_reset_inverse    : 0:00:00.002000 (0.06%)\n",
      "approx_mask_update           : 0:00:00.082006 (2.55%)\n",
      "approx_sparse                : 0:00:00.917022 (28.56%)\n",
      "bert.attention.output        : 0:00:00.162011 (5.05%)\n",
      "bert.attention.probs.dropout : 0:00:00.001000 (0.03%)\n",
      "bert.attention.qkv           : 0:00:00.240004 (7.47%)\n",
      "bert.attention.scores.matmul : 0:00:00.048999 (1.53%)\n",
      "bert.intermediate            : 0:00:00.111025 (3.46%)\n",
      "bert.output                  : 0:00:00.100998 (3.15%)\n",
      "sparselinear                 : 0:00:00.507026 (15.79%)\n",
      "sparselinear.gather          : 0:00:00.104996 (3.27%)\n",
      "sparselinear.linear          : 0:00:00.285007 (8.88%)\n",
      "sparselinear.scatter_        : 0:00:00.109022 (3.40%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.556016445159912, 2.2102506323294207, 452.43737763173175)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(sparse)\n",
    "sparse.timer_reset()\n",
    "benchmark_device = 'cuda'\n",
    "benchmark_batch_size = 32\n",
    "\n",
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(benchmark_device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse_bert=sparse_bert.to(benchmark_device)\n",
    "approx_bert=approx_bert.to(benchmark_device)\n",
    "time_approx = benchmark(\n",
    "    eval = lambda batch: approx_eval(sparse_bert, approx_bert, batch=batch, fc=lambda x: x),\n",
    "    batch_size = benchmark_batch_size,\n",
    "    WARM = 3,\n",
    "    N = 25,\n",
    "    device = benchmark_device,\n",
    "    end_warm = lambda: sparse.timer_reset()\n",
    ")\n",
    "sparse.timer_report()\n",
    "time_approx\n",
    "\n",
    "# bert.attention.output        : 0:00:00.545988 (3.04%)\n",
    "# bert.attention.probs.dropout : 0:00:00.006996 (0.04%)\n",
    "# bert.attention.qkv           : 0:00:01.473990 (8.20%)\n",
    "# bert.attention.scores.matmul : 0:00:00.113033 (0.63%)\n",
    "# bert.intermediate            : 0:00:02.113082 (11.75%)\n",
    "# bert.output                  : 0:00:01.848977 (10.28%)\n",
    "# sparselinear.linear          : 0:00:03.801073 (21.14%)\n",
    "\n",
    "# bert.attention.output        : 0:00:01.103962 (2.75%)\n",
    "# bert.attention.probs.dropout : 0:00:00.010004 (0.02%)\n",
    "# bert.attention.qkv           : 0:00:02.440944 (6.07%)\n",
    "# bert.attention.scores.matmul : 0:00:00.534112 (1.33%)\n",
    "# bert.intermediate            : 0:00:02.811061 (6.99%)\n",
    "# bert.output                  : 0:00:02.548062 (6.34%)\n",
    "# sparselinear                 : 0:00:07.770034 (19.33%)\n",
    "# sparselinear.gather          : 0:00:01.343004 (3.34%)\n",
    "# sparselinear.linear          : 0:00:04.463333 (11.11%)\n",
    "# sparselinear.scatter_        : 0:00:01.947706 (4.85%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 12.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.742016315460205, 2.474454993551428, 404.12939520260323)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = bert.to(benchmark_device)\n",
    "time_bert = benchmark(\n",
    "    lambda batch: eval(bert, batch=batch, fc=lambda x: x), \n",
    "    batch_size = benchmark_batch_size,\n",
    "    WARM = 3,\n",
    "    N=25,\n",
    "    device = benchmark_device\n",
    ")\n",
    "time_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2).unsqueeze(-1).repeat(1, 1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7b3ac0126d0d6fea024471ce24e510948bf6332f7ae1a66cdcb4ee9887514e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
