{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, math, time, sys, os, tqdm\n",
    "import numpy as np\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 207565.86it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 162069.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert-mini\n",
      "Trainer.load: Loading... saves/cls_bert-mini.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 202128.23it/s]\n",
      "100%|██████████| 7600/7600 [00:00<00:00, 243220.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:1012, avg_len:236.477525, count:120000\n",
      "Classification Dataset Stat.: name:AG_NEWS, nclass:5, max_len:892, avg_len:235.2992105263158, count:7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer.__init__: Model initialized. model = bert-mini\n",
      "Trainer.load: Loading... saves/cls_bert-mini.pth\n",
      "Trainer.load: saves/att_approx_8_bert-mini.pth\n",
      "approx trained 37500\n"
     ]
    }
   ],
   "source": [
    "from trainer.classification import Trainer\n",
    "from trainer.attention_approx import Trainer as ApproxTrainer\n",
    "batch_size = 4\n",
    "device = 1\n",
    "\n",
    "trainer = Trainer(batch_size=batch_size, model='bert-mini', device=device)\n",
    "trainer.load()\n",
    "trainer.model.eval()\n",
    "bert = trainer.model.bert\n",
    "fc = trainer.model.classifier\n",
    "batch = trainer.get_batch()\n",
    "test_batch = trainer.get_batch(test=False)\n",
    "\n",
    "approx_trainer = ApproxTrainer(batch_size=batch_size, factor=8, model=trainer.model_type, device=trainer.device)\n",
    "approx_trainer.load()\n",
    "approx_bert = approx_trainer.bert\n",
    "approx_bert = approx_bert.eval()\n",
    "print('approx trained', approx_trainer.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.sparse_token' from 'f:\\\\Library\\\\discrete_edge_learning\\\\models\\\\sparse_token.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import models.sparse_token as sparse\n",
    "importlib.reload(sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(trainer.device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n",
      "apply input mask, before softmax. input_mask:torch.Size([4, 71]), attention_scores:torch.Size([4, 4, 71, 71])\n",
      "SelfAttention.forward: last_attention_probs backuped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([1, 2, 4, 1], device='cuda:1'),\n",
       "  tensor([1, 2, 4, 1], device='cuda:1')),\n",
       " (tensor([1, 2, 4, 1], device='cuda:1'),\n",
       "  tensor([1, 2, 4, 1], device='cuda:1')))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_fc(lm_output, fc=fc, batch=batch):\n",
    "    last_hidden = lm_output.last_hidden_state[:,0,:]\n",
    "    x = fc(last_hidden)\n",
    "    return torch.argmax(x, dim=-1), batch.labels, lm_output\n",
    "\n",
    "def eval(bert, fc=fc, batch=batch):\n",
    "    lm_output = bert(\n",
    "        input_ids = batch.input_ids, \n",
    "        attention_mask = batch.attention_masks,\n",
    "        output_hidden_states = True,\n",
    "        output_attentions = True,\n",
    "    )\n",
    "    return eval_fc(lm_output, fc=fc, batch=batch)\n",
    "\n",
    "def approx_eval(sparse_bert, approx_bert, fc=fc, batch=batch):\n",
    "    lm_output = sparse.run_bert_with_approx(\n",
    "        sparse_bert, \n",
    "        approx_bert, \n",
    "        {\n",
    "            'input_ids': batch.input_ids,\n",
    "            'attention_mask': batch.attention_masks,\n",
    "            'output_hidden_states': True,\n",
    "            'output_attentions': True,\n",
    "        },\n",
    "        ks = [0.25]*len(sparse_bert.encoder.layer),\n",
    "    )\n",
    "    return eval_fc(lm_output, fc=fc, batch=batch)\n",
    "    \n",
    "eval(bert)[:2], approx_eval(sparse_bert, approx_bert)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:07<00:00, 62.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_att                   : 0:00:02.171075 (16.44%)\n",
      "approx_mask_reset            : 0:00:00.062477 (0.47%)\n",
      "approx_mask_reset_inverse    : 0:00:00 (0.00%)\n",
      "approx_mask_update           : 0:00:00.624894 (4.73%)\n",
      "approx_sparse                : 0:00:03.688058 (27.93%)\n",
      "bert.attention.output        : 0:00:00.499852 (3.79%)\n",
      "bert.attention.probs.dropout : 0:00:00.046869 (0.35%)\n",
      "bert.attention.qkv           : 0:00:01.156020 (8.76%)\n",
      "bert.attention.scores.matmul : 0:00:00.203351 (1.54%)\n",
      "bert.intermediate            : 0:00:00.312938 (2.37%)\n",
      "bert.output                  : 0:00:00.531508 (4.03%)\n",
      "sparselinear                 : 0:00:02.000044 (15.15%)\n",
      "sparselinear.gather          : 0:00:00.469263 (3.55%)\n",
      "sparselinear.linear          : 0:00:00.671580 (5.09%)\n",
      "sparselinear.scatter_        : 0:00:00.765460 (5.80%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9146052631578947, 0.9146052631578947, False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(sparse)\n",
    "def accuracy(batch_eval, N=7600//16, return_lm=False):\n",
    "    trainer.seed()\n",
    "    trainer.dataset.batch_size = 16\n",
    "    acc_sum = 0\n",
    "    for i in tqdm.tqdm(range(N)):\n",
    "        batch = trainer.get_batch(test=True)\n",
    "        with torch.no_grad():\n",
    "            output, label, _ = batch_eval(batch)\n",
    "        acc_sum += torch.mean((output == label) * 1.0)\n",
    "    if return_lm: return acc_sum.item() / N, _\n",
    "    return acc_sum.item() / N\n",
    "\n",
    "# setup for evaluation\n",
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(trainer.device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse_bert = sparse_bert.to(trainer.device)\n",
    "approx_bert = approx_bert.to(trainer.device)\n",
    "bert = bert.to(trainer.device)\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse.timer_reset()\n",
    "acc_approx, lm = accuracy(\n",
    "    lambda batch: approx_eval(sparse_bert, approx_bert, batch=batch),\n",
    "    return_lm = True,\n",
    ")\n",
    "acc_bert = acc_approx\n",
    "#acc_bert = accuracy(lambda batch: eval(bert, batch=batch))\n",
    "sparse.timer_report()\n",
    "acc_bert, acc_approx, abs(acc_approx - 0.9236111111111112) < 0.001\n",
    "\n",
    "#bert-mini 4 0.25\n",
    "#sum, sum = 0.9217105263157894\n",
    "#sum, max = 0.9236842105263158\n",
    "#max, sum = 0.9223684210526316\n",
    "#max, max = 0.9221052631578948\n",
    "#no token impact = 0.9239473684210526\n",
    "\n",
    "#bert-mini 8 0.25\n",
    "#sum, sum = 0.9178947368421052\n",
    "#sum, max = 0.9111842105263158\n",
    "#max, sum = 0.9157894736842105\n",
    "#max, max = 0.9102631578947369\n",
    "#no token impact = 0.9146052631578947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9379e-03, 2.9608e-04, 3.4527e-04, 2.4866e-03, 2.9915e-04, 5.1534e-03,\n",
      "         5.3374e-03],\n",
      "        [1.6033e-01, 9.8515e-02, 9.1877e-04, 7.9570e-06, 1.2104e-04, 7.4521e-04,\n",
      "         3.1750e-03]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_grid(grid):\n",
    "    plt.imshow(grid.cpu().detach().numpy())\n",
    "    #plt.colorbar()\n",
    "    plt.show()\n",
    "plot_grid(lm.attentions[-4][0][0][:50, :50])\n",
    "print(lm.attentions[-2][0][0][:2, :7])\n",
    "#tensor([[0.0246, 0.0012, 0.0206, 0.0003, 0.0000, 0.0002, 0.0049]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(eval, batch_size=8, N=100, WARM=20, amp=False, device=trainer.device, end_warm=None):\n",
    "    assert WARM < (N * 0.33)\n",
    "    trainer.dataset.batch_size = batch_size\n",
    "    batch = trainer.get_batch(test=True)\n",
    "    batch = batch.to(device)\n",
    "    assert batch.input_ids.shape[0] == batch_size\n",
    "    for i in tqdm.tqdm(range(N)):\n",
    "        if i == WARM: \n",
    "            t = time.time()\n",
    "            if not end_warm is None: end_warm()\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=amp):\n",
    "            eval(batch)\n",
    "    t = time.time() - t\n",
    "    t_item = t / (batch_size * (N-WARM))\n",
    "    return t, t_item * 1000, 1.0/t_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_att                   : 0:00:00.953405 (18.38%)\n",
      "approx_mask_reset            : 0:00:00 (0.00%)\n",
      "approx_mask_reset_inverse    : 0:00:00 (0.00%)\n",
      "approx_mask_update           : 0:00:00.328132 (6.33%)\n",
      "approx_sparse                : 0:00:01.421596 (27.40%)\n",
      "bert.attention.output        : 0:00:00.124890 (2.41%)\n",
      "bert.attention.probs.dropout : 0:00:00 (0.00%)\n",
      "bert.attention.qkv           : 0:00:00.343886 (6.63%)\n",
      "bert.attention.scores.matmul : 0:00:00.046874 (0.90%)\n",
      "bert.intermediate            : 0:00:00.171860 (3.31%)\n",
      "bert.output                  : 0:00:00.296903 (5.72%)\n",
      "sparselinear                 : 0:00:00.750029 (14.46%)\n",
      "sparselinear.gather          : 0:00:00.124923 (2.41%)\n",
      "sparselinear.linear          : 0:00:00.281133 (5.42%)\n",
      "sparselinear.scatter_        : 0:00:00.343973 (6.63%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.703131914138794, 0.9599190036004239, 1041.7545608006947)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(sparse)\n",
    "sparse.timer_reset()\n",
    "benchmark_device = 'cuda'\n",
    "benchmark_batch_size = 128\n",
    "\n",
    "sparse_bert = sparse.SparseBertModel(bert.config)\n",
    "sparse_bert.to(benchmark_device)\n",
    "sparse_bert.eval()\n",
    "sparse_bert.load_state_dict(bert.state_dict())\n",
    "sparse.set_print(sparse_bert, False)\n",
    "sparse.set_backup_last_inputs(sparse_bert, False)\n",
    "sparse.set_output_masking(sparse_bert, False)\n",
    "\n",
    "sparse_bert=sparse_bert.to(benchmark_device)\n",
    "approx_bert=approx_bert.to(benchmark_device)\n",
    "time_approx = benchmark(\n",
    "    eval = lambda batch: approx_eval(sparse_bert, approx_bert, batch=batch, fc=lambda x: x),\n",
    "    batch_size = benchmark_batch_size,\n",
    "    WARM = 3,\n",
    "    N = 25,\n",
    "    device = benchmark_device,\n",
    "    end_warm = lambda: sparse.timer_reset()\n",
    ")\n",
    "sparse.timer_report()\n",
    "time_approx\n",
    "\n",
    "# bert.attention.output        : 0:00:00.545988 (3.04%)\n",
    "# bert.attention.probs.dropout : 0:00:00.006996 (0.04%)\n",
    "# bert.attention.qkv           : 0:00:01.473990 (8.20%)\n",
    "# bert.attention.scores.matmul : 0:00:00.113033 (0.63%)\n",
    "# bert.intermediate            : 0:00:02.113082 (11.75%)\n",
    "# bert.output                  : 0:00:01.848977 (10.28%)\n",
    "# sparselinear.linear          : 0:00:03.801073 (21.14%)\n",
    "\n",
    "# bert.attention.output        : 0:00:01.103962 (2.75%)\n",
    "# bert.attention.probs.dropout : 0:00:00.010004 (0.02%)\n",
    "# bert.attention.qkv           : 0:00:02.440944 (6.07%)\n",
    "# bert.attention.scores.matmul : 0:00:00.534112 (1.33%)\n",
    "# bert.intermediate            : 0:00:02.811061 (6.99%)\n",
    "# bert.output                  : 0:00:02.548062 (6.34%)\n",
    "# sparselinear                 : 0:00:07.770034 (19.33%)\n",
    "# sparselinear.gather          : 0:00:01.343004 (3.34%)\n",
    "# sparselinear.linear          : 0:00:04.463333 (11.11%)\n",
    "# sparselinear.scatter_        : 0:00:01.947706 (4.85%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 18.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.343578815460205, 0.4771231588992205, 2095.8949096227443)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = bert.to(benchmark_device)\n",
    "time_bert = benchmark(\n",
    "    lambda batch: eval(bert, batch=batch, fc=lambda x: x), \n",
    "    batch_size = benchmark_batch_size,\n",
    "    WARM = 3,\n",
    "    N=25,\n",
    "    device = benchmark_device\n",
    ")\n",
    "time_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2).unsqueeze(-1).repeat(1, 1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLayer(\n",
       "  (attention): BertAttention(\n",
       "    (self): BertSelfAttention(\n",
       "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "      (LayerNorm): LayerNorm((96,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): BertIntermediate(\n",
       "    (dense): Linear(in_features=96, out_features=3072, bias=True)\n",
       "  )\n",
       "  (output): BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=96, bias=True)\n",
       "    (LayerNorm): LayerNorm((96,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_bert.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7b3ac0126d0d6fea024471ce24e510948bf6332f7ae1a66cdcb4ee9887514e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
